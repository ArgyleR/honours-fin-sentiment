{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2699e33ac30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "Cell In[15], line 162, in update_graph(\n",
      "    selected_metric='loss',\n",
      "    pivot_by='text_selection_method',\n",
      "    view_mode='individual'\n",
      ")\n",
      "    154     val_fig.update_layout(\n",
      "    155         title=f\"Validation {selected_metric.capitalize()} Summary Over Epochs\",\n",
      "    156         xaxis_title=\"Epoch\",\n",
      "    157         yaxis_title=f\"Validation {selected_metric.capitalize()}\"\n",
      "    158     )\n",
      "    160 else:  # Individual mode\n",
      "    161     # Plot for training metrics (individual performance)\n",
      "--> 162     train_fig = px.line(df, x=\"epoch\", y=train_metric_col, color=pivot_by, markers=True,\n",
      "        train_metric_col = 'train_loss'\n",
      "        df =       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns]\n",
      "        px = <module 'plotly.express' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\plotly\\\\express\\\\__init__.py'>\n",
      "        pivot_by = 'text_selection_method'\n",
      "        selected_metric = 'loss'\n",
      "    163                         labels={\n",
      "    164                             \"epoch\": \"Epoch\",\n",
      "    165                             train_metric_col: f\"Train {selected_metric.capitalize()}\",\n",
      "    166                             pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
      "    167                         },\n",
      "    168                         title=f\"Train {selected_metric.capitalize()} Over Epochs\")\n",
      "    170     # Plot for validation metrics (individual performance)\n",
      "    171     val_fig = px.line(df, x=\"epoch\", y=val_metric_col, color=pivot_by, markers=True,\n",
      "    172                       labels={\n",
      "    173                           \"epoch\": \"Epoch\",\n",
      "   (...)\n",
      "    176                       },\n",
      "    177                       title=f\"Validation {selected_metric.capitalize()} Over Epochs\")\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_chart_types.py:264, in line(\n",
      "    data_frame=      epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns],\n",
      "    x='epoch',\n",
      "    y='train_loss',\n",
      "    line_group=None,\n",
      "    color='text_selection_method',\n",
      "    line_dash=None,\n",
      "    symbol=None,\n",
      "    hover_name=None,\n",
      "    hover_data=None,\n",
      "    custom_data=None,\n",
      "    text=None,\n",
      "    facet_row=None,\n",
      "    facet_col=None,\n",
      "    facet_col_wrap=0,\n",
      "    facet_row_spacing=None,\n",
      "    facet_col_spacing=None,\n",
      "    error_x=None,\n",
      "    error_x_minus=None,\n",
      "    error_y=None,\n",
      "    error_y_minus=None,\n",
      "    animation_frame=None,\n",
      "    animation_group=None,\n",
      "    category_orders=None,\n",
      "    labels={'epoch': 'Epoch', 'text_selection_method': 'Text selection method', 'train_loss': 'Train Loss'},\n",
      "    orientation=None,\n",
      "    color_discrete_sequence=None,\n",
      "    color_discrete_map=None,\n",
      "    line_dash_sequence=None,\n",
      "    line_dash_map=None,\n",
      "    symbol_sequence=None,\n",
      "    symbol_map=None,\n",
      "    markers=True,\n",
      "    log_x=False,\n",
      "    log_y=False,\n",
      "    range_x=None,\n",
      "    range_y=None,\n",
      "    line_shape=None,\n",
      "    render_mode='auto',\n",
      "    title='Train Loss Over Epochs',\n",
      "    template=None,\n",
      "    width=None,\n",
      "    height=None\n",
      ")\n",
      "    216 def line(\n",
      "    217     data_frame=None,\n",
      "    218     x=None,\n",
      "   (...)\n",
      "    258     height=None,\n",
      "    259 ) -> go.Figure:\n",
      "    260     \"\"\"\n",
      "    261     In a 2D line plot, each row of `data_frame` is represented as vertex of\n",
      "    262     a polyline mark in 2D space.\n",
      "    263     \"\"\"\n",
      "--> 264     return make_figure(args=locals(), constructor=go.Scatter)\n",
      "        go = <module 'plotly.graph_objs' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\plotly\\\\graph_objs\\\\__init__.py'>\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_core.py:2130, in make_figure(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': 'text_selection_method', 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame':       epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'error_x': None, 'error_x_minus': None, ...},\n",
      "    constructor=<class 'plotly.graph_objs._scatter.Scatter'>,\n",
      "    trace_patch={'line': {'shape': None}, 'mode': 'lines+markers'},\n",
      "    layout_patch={}\n",
      ")\n",
      "   2126 trace_specs, grouped_mappings, sizeref, show_colorbar = infer_config(\n",
      "   2127     args, constructor, trace_patch, layout_patch\n",
      "   2128 )\n",
      "   2129 grouper = [x.grouper or one_group for x in grouped_mappings] or [one_group]\n",
      "-> 2130 groups, orders = get_groups_and_orders(args, grouper)\n",
      "        args = {'data_frame':       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'x': 'epoch', 'y': 'train_loss', 'line_group': None, 'color': 'text_selection_method', 'line_dash': None, 'symbol': None, 'hover_name': None, 'hover_data': None, 'custom_data': None, 'text': None, 'facet_row': None, 'facet_col': None, 'facet_col_wrap': 0, 'facet_row_spacing': None, 'facet_col_spacing': None, 'error_x': None, 'error_x_minus': None, 'error_y': None, 'error_y_minus': None, 'animation_frame': None, 'animation_group': None, 'category_orders': None, 'labels': {'epoch': 'Epoch', 'train_loss': 'Train Loss', 'text_selection_method': 'Text selection method'}, 'orientation': None, 'color_discrete_sequence': None, 'color_discrete_map': None, 'line_dash_sequence': None, 'line_dash_map': None, 'symbol_sequence': None, 'symbol_map': None, 'markers': True, 'log_x': False, 'log_y': False, 'range_x': None, 'range_y': None, 'line_shape': None, 'render_mode': 'auto', 'title': 'Train Loss Over Epochs', 'template': None, 'width': None, 'height': None}\n",
      "        grouper = ['text_selection_method', <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>]\n",
      "   2132 col_labels = []\n",
      "   2133 row_labels = []\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_core.py:2064, in get_groups_and_orders(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': 'text_selection_method', 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame':       epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'error_x': None, 'error_x_minus': None, ...},\n",
      "    grouper=['text_selection_method', <function one_group>, <function one_group>, <function one_group>, <function one_group>, <function one_group>, <function one_group>]\n",
      ")\n",
      "   2062 else:\n",
      "   2063     if col not in unique_cache:\n",
      "-> 2064         unique_cache[col] = list(args[\"data_frame\"][col].unique())\n",
      "        unique_cache = {}\n",
      "        col = 'text_selection_method'\n",
      "        args[\"data_frame\"] =       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns]\n",
      "        args = {'data_frame':       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'x': 'epoch', 'y': 'train_loss', 'line_group': None, 'color': 'text_selection_method', 'line_dash': None, 'symbol': None, 'hover_name': None, 'hover_data': None, 'custom_data': None, 'text': None, 'facet_row': None, 'facet_col': None, 'facet_col_wrap': 0, 'facet_row_spacing': None, 'facet_col_spacing': None, 'error_x': None, 'error_x_minus': None, 'error_y': None, 'error_y_minus': None, 'animation_frame': None, 'animation_group': None, 'category_orders': None, 'labels': {'epoch': 'Epoch', 'train_loss': 'Train Loss', 'text_selection_method': 'Text selection method'}, 'orientation': None, 'color_discrete_sequence': None, 'color_discrete_map': None, 'line_dash_sequence': None, 'line_dash_map': None, 'symbol_sequence': None, 'symbol_map': None, 'markers': True, 'log_x': False, 'log_y': False, 'range_x': None, 'range_y': None, 'line_shape': None, 'render_mode': 'auto', 'title': 'Train Loss Over Epochs', 'template': None, 'width': None, 'height': None}\n",
      "   2065     uniques = unique_cache[col]\n",
      "   2066     if len(uniques) == 1:\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\series.py:2407, in Series.unique(\n",
      "    self=0       [TFIDF, 5]\n",
      "1       [TFIDF, 5]\n",
      "2       [T...ext_selection_method, Length: 1080, dtype: object\n",
      ")\n",
      "   2344 def unique(self) -> ArrayLike:  # pylint: disable=useless-parent-delegation\n",
      "   2345     \"\"\"\n",
      "   2346     Return unique values of Series object.\n",
      "   2347 \n",
      "   (...)\n",
      "   2405     Categories (3, object): ['a' < 'b' < 'c']\n",
      "   2406     \"\"\"\n",
      "-> 2407     return super().unique()\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\base.py:1025, in IndexOpsMixin.unique(\n",
      "    self=0       [TFIDF, 5]\n",
      "1       [TFIDF, 5]\n",
      "2       [T...ext_selection_method, Length: 1080, dtype: object\n",
      ")\n",
      "   1023     result = values.unique()\n",
      "   1024 else:\n",
      "-> 1025     result = algorithms.unique1d(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "        algorithms.unique1d = <function unique at 0x00000269FF354860>\n",
      "        algorithms = <module 'pandas.core.algorithms' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\pandas\\\\core\\\\algorithms.py'>\n",
      "   1026 return result\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:401, in unique(\n",
      "    values=array([list(['TFIDF', 5]), list(['TFIDF', 5]), l...F', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      ")\n",
      "    307 def unique(values):\n",
      "    308     \"\"\"\n",
      "    309     Return unique values based on a hash table.\n",
      "    310 \n",
      "   (...)\n",
      "    399     array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\n",
      "    400     \"\"\"\n",
      "--> 401     return unique_with_mask(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:440, in unique_with_mask(\n",
      "    values=array([list(['TFIDF', 5]), list(['TFIDF', 5]), l...F', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object),\n",
      "    mask=None\n",
      ")\n",
      "    438 table = hashtable(len(values))\n",
      "    439 if mask is None:\n",
      "--> 440     uniques = table.unique(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "        table = <pandas._libs.hashtable.PyObjectHashTable object at 0x000002699EDE7530>\n",
      "    441     uniques = _reconstruct_data(uniques, original.dtype, original)\n",
      "    442     return uniques\n",
      "\n",
      "File pandas\\\\_libs\\\\hashtable_class_helper.pxi:7248, in pandas._libs.hashtable.PyObjectHashTable.unique()\n",
      "\n",
      "File pandas\\\\_libs\\\\hashtable_class_helper.pxi:7195, in pandas._libs.hashtable.PyObjectHashTable._unique()\n",
      "\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "Cell In[15], line 162, in update_graph(\n",
      "    selected_metric='loss',\n",
      "    pivot_by='text_selection_method',\n",
      "    view_mode='individual'\n",
      ")\n",
      "    154     val_fig.update_layout(\n",
      "    155         title=f\"Validation {selected_metric.capitalize()} Summary Over Epochs\",\n",
      "    156         xaxis_title=\"Epoch\",\n",
      "    157         yaxis_title=f\"Validation {selected_metric.capitalize()}\"\n",
      "    158     )\n",
      "    160 else:  # Individual mode\n",
      "    161     # Plot for training metrics (individual performance)\n",
      "--> 162     train_fig = px.line(df, x=\"epoch\", y=train_metric_col, color=pivot_by, markers=True,\n",
      "        train_metric_col = 'train_loss'\n",
      "        df =       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns]\n",
      "        px = <module 'plotly.express' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\plotly\\\\express\\\\__init__.py'>\n",
      "        pivot_by = 'text_selection_method'\n",
      "        selected_metric = 'loss'\n",
      "    163                         labels={\n",
      "    164                             \"epoch\": \"Epoch\",\n",
      "    165                             train_metric_col: f\"Train {selected_metric.capitalize()}\",\n",
      "    166                             pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
      "    167                         },\n",
      "    168                         title=f\"Train {selected_metric.capitalize()} Over Epochs\")\n",
      "    170     # Plot for validation metrics (individual performance)\n",
      "    171     val_fig = px.line(df, x=\"epoch\", y=val_metric_col, color=pivot_by, markers=True,\n",
      "    172                       labels={\n",
      "    173                           \"epoch\": \"Epoch\",\n",
      "   (...)\n",
      "    176                       },\n",
      "    177                       title=f\"Validation {selected_metric.capitalize()} Over Epochs\")\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_chart_types.py:264, in line(\n",
      "    data_frame=      epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns],\n",
      "    x='epoch',\n",
      "    y='train_loss',\n",
      "    line_group=None,\n",
      "    color='text_selection_method',\n",
      "    line_dash=None,\n",
      "    symbol=None,\n",
      "    hover_name=None,\n",
      "    hover_data=None,\n",
      "    custom_data=None,\n",
      "    text=None,\n",
      "    facet_row=None,\n",
      "    facet_col=None,\n",
      "    facet_col_wrap=0,\n",
      "    facet_row_spacing=None,\n",
      "    facet_col_spacing=None,\n",
      "    error_x=None,\n",
      "    error_x_minus=None,\n",
      "    error_y=None,\n",
      "    error_y_minus=None,\n",
      "    animation_frame=None,\n",
      "    animation_group=None,\n",
      "    category_orders=None,\n",
      "    labels={'epoch': 'Epoch', 'text_selection_method': 'Text selection method', 'train_loss': 'Train Loss'},\n",
      "    orientation=None,\n",
      "    color_discrete_sequence=None,\n",
      "    color_discrete_map=None,\n",
      "    line_dash_sequence=None,\n",
      "    line_dash_map=None,\n",
      "    symbol_sequence=None,\n",
      "    symbol_map=None,\n",
      "    markers=True,\n",
      "    log_x=False,\n",
      "    log_y=False,\n",
      "    range_x=None,\n",
      "    range_y=None,\n",
      "    line_shape=None,\n",
      "    render_mode='auto',\n",
      "    title='Train Loss Over Epochs',\n",
      "    template=None,\n",
      "    width=None,\n",
      "    height=None\n",
      ")\n",
      "    216 def line(\n",
      "    217     data_frame=None,\n",
      "    218     x=None,\n",
      "   (...)\n",
      "    258     height=None,\n",
      "    259 ) -> go.Figure:\n",
      "    260     \"\"\"\n",
      "    261     In a 2D line plot, each row of `data_frame` is represented as vertex of\n",
      "    262     a polyline mark in 2D space.\n",
      "    263     \"\"\"\n",
      "--> 264     return make_figure(args=locals(), constructor=go.Scatter)\n",
      "        go = <module 'plotly.graph_objs' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\plotly\\\\graph_objs\\\\__init__.py'>\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_core.py:2130, in make_figure(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': 'text_selection_method', 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame':       epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'error_x': None, 'error_x_minus': None, ...},\n",
      "    constructor=<class 'plotly.graph_objs._scatter.Scatter'>,\n",
      "    trace_patch={'line': {'shape': None}, 'mode': 'lines+markers'},\n",
      "    layout_patch={}\n",
      ")\n",
      "   2126 trace_specs, grouped_mappings, sizeref, show_colorbar = infer_config(\n",
      "   2127     args, constructor, trace_patch, layout_patch\n",
      "   2128 )\n",
      "   2129 grouper = [x.grouper or one_group for x in grouped_mappings] or [one_group]\n",
      "-> 2130 groups, orders = get_groups_and_orders(args, grouper)\n",
      "        args = {'data_frame':       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'x': 'epoch', 'y': 'train_loss', 'line_group': None, 'color': 'text_selection_method', 'line_dash': None, 'symbol': None, 'hover_name': None, 'hover_data': None, 'custom_data': None, 'text': None, 'facet_row': None, 'facet_col': None, 'facet_col_wrap': 0, 'facet_row_spacing': None, 'facet_col_spacing': None, 'error_x': None, 'error_x_minus': None, 'error_y': None, 'error_y_minus': None, 'animation_frame': None, 'animation_group': None, 'category_orders': None, 'labels': {'epoch': 'Epoch', 'train_loss': 'Train Loss', 'text_selection_method': 'Text selection method'}, 'orientation': None, 'color_discrete_sequence': None, 'color_discrete_map': None, 'line_dash_sequence': None, 'line_dash_map': None, 'symbol_sequence': None, 'symbol_map': None, 'markers': True, 'log_x': False, 'log_y': False, 'range_x': None, 'range_y': None, 'line_shape': None, 'render_mode': 'auto', 'title': 'Train Loss Over Epochs', 'template': None, 'width': None, 'height': None}\n",
      "        grouper = ['text_selection_method', <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>]\n",
      "   2132 col_labels = []\n",
      "   2133 row_labels = []\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_core.py:2064, in get_groups_and_orders(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': 'text_selection_method', 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame':       epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'error_x': None, 'error_x_minus': None, ...},\n",
      "    grouper=['text_selection_method', <function one_group>, <function one_group>, <function one_group>, <function one_group>, <function one_group>, <function one_group>]\n",
      ")\n",
      "   2062 else:\n",
      "   2063     if col not in unique_cache:\n",
      "-> 2064         unique_cache[col] = list(args[\"data_frame\"][col].unique())\n",
      "        unique_cache = {}\n",
      "        col = 'text_selection_method'\n",
      "        args[\"data_frame\"] =       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns]\n",
      "        args = {'data_frame':       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'x': 'epoch', 'y': 'train_loss', 'line_group': None, 'color': 'text_selection_method', 'line_dash': None, 'symbol': None, 'hover_name': None, 'hover_data': None, 'custom_data': None, 'text': None, 'facet_row': None, 'facet_col': None, 'facet_col_wrap': 0, 'facet_row_spacing': None, 'facet_col_spacing': None, 'error_x': None, 'error_x_minus': None, 'error_y': None, 'error_y_minus': None, 'animation_frame': None, 'animation_group': None, 'category_orders': None, 'labels': {'epoch': 'Epoch', 'train_loss': 'Train Loss', 'text_selection_method': 'Text selection method'}, 'orientation': None, 'color_discrete_sequence': None, 'color_discrete_map': None, 'line_dash_sequence': None, 'line_dash_map': None, 'symbol_sequence': None, 'symbol_map': None, 'markers': True, 'log_x': False, 'log_y': False, 'range_x': None, 'range_y': None, 'line_shape': None, 'render_mode': 'auto', 'title': 'Train Loss Over Epochs', 'template': None, 'width': None, 'height': None}\n",
      "   2065     uniques = unique_cache[col]\n",
      "   2066     if len(uniques) == 1:\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\series.py:2407, in Series.unique(\n",
      "    self=0       [TFIDF, 5]\n",
      "1       [TFIDF, 5]\n",
      "2       [T...ext_selection_method, Length: 1080, dtype: object\n",
      ")\n",
      "   2344 def unique(self) -> ArrayLike:  # pylint: disable=useless-parent-delegation\n",
      "   2345     \"\"\"\n",
      "   2346     Return unique values of Series object.\n",
      "   2347 \n",
      "   (...)\n",
      "   2405     Categories (3, object): ['a' < 'b' < 'c']\n",
      "   2406     \"\"\"\n",
      "-> 2407     return super().unique()\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\base.py:1025, in IndexOpsMixin.unique(\n",
      "    self=0       [TFIDF, 5]\n",
      "1       [TFIDF, 5]\n",
      "2       [T...ext_selection_method, Length: 1080, dtype: object\n",
      ")\n",
      "   1023     result = values.unique()\n",
      "   1024 else:\n",
      "-> 1025     result = algorithms.unique1d(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "        algorithms.unique1d = <function unique at 0x00000269FF354860>\n",
      "        algorithms = <module 'pandas.core.algorithms' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\pandas\\\\core\\\\algorithms.py'>\n",
      "   1026 return result\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:401, in unique(\n",
      "    values=array([list(['TFIDF', 5]), list(['TFIDF', 5]), l...F', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      ")\n",
      "    307 def unique(values):\n",
      "    308     \"\"\"\n",
      "    309     Return unique values based on a hash table.\n",
      "    310 \n",
      "   (...)\n",
      "    399     array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\n",
      "    400     \"\"\"\n",
      "--> 401     return unique_with_mask(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:440, in unique_with_mask(\n",
      "    values=array([list(['TFIDF', 5]), list(['TFIDF', 5]), l...F', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object),\n",
      "    mask=None\n",
      ")\n",
      "    438 table = hashtable(len(values))\n",
      "    439 if mask is None:\n",
      "--> 440     uniques = table.unique(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "        table = <pandas._libs.hashtable.PyObjectHashTable object at 0x000002699EB016D0>\n",
      "    441     uniques = _reconstruct_data(uniques, original.dtype, original)\n",
      "    442     return uniques\n",
      "\n",
      "File pandas\\\\_libs\\\\hashtable_class_helper.pxi:7248, in pandas._libs.hashtable.PyObjectHashTable.unique()\n",
      "\n",
      "File pandas\\\\_libs\\\\hashtable_class_helper.pxi:7195, in pandas._libs.hashtable.PyObjectHashTable._unique()\n",
      "\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "Cell In[15], line 162, in update_graph(\n",
      "    selected_metric='loss',\n",
      "    pivot_by='text_selection_method',\n",
      "    view_mode='individual'\n",
      ")\n",
      "    154     val_fig.update_layout(\n",
      "    155         title=f\"Validation {selected_metric.capitalize()} Summary Over Epochs\",\n",
      "    156         xaxis_title=\"Epoch\",\n",
      "    157         yaxis_title=f\"Validation {selected_metric.capitalize()}\"\n",
      "    158     )\n",
      "    160 else:  # Individual mode\n",
      "    161     # Plot for training metrics (individual performance)\n",
      "--> 162     train_fig = px.line(df, x=\"epoch\", y=train_metric_col, color=pivot_by, markers=True,\n",
      "        train_metric_col = 'train_loss'\n",
      "        df =       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns]\n",
      "        px = <module 'plotly.express' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\plotly\\\\express\\\\__init__.py'>\n",
      "        pivot_by = 'text_selection_method'\n",
      "        selected_metric = 'loss'\n",
      "    163                         labels={\n",
      "    164                             \"epoch\": \"Epoch\",\n",
      "    165                             train_metric_col: f\"Train {selected_metric.capitalize()}\",\n",
      "    166                             pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
      "    167                         },\n",
      "    168                         title=f\"Train {selected_metric.capitalize()} Over Epochs\")\n",
      "    170     # Plot for validation metrics (individual performance)\n",
      "    171     val_fig = px.line(df, x=\"epoch\", y=val_metric_col, color=pivot_by, markers=True,\n",
      "    172                       labels={\n",
      "    173                           \"epoch\": \"Epoch\",\n",
      "   (...)\n",
      "    176                       },\n",
      "    177                       title=f\"Validation {selected_metric.capitalize()} Over Epochs\")\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_chart_types.py:264, in line(\n",
      "    data_frame=      epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns],\n",
      "    x='epoch',\n",
      "    y='train_loss',\n",
      "    line_group=None,\n",
      "    color='text_selection_method',\n",
      "    line_dash=None,\n",
      "    symbol=None,\n",
      "    hover_name=None,\n",
      "    hover_data=None,\n",
      "    custom_data=None,\n",
      "    text=None,\n",
      "    facet_row=None,\n",
      "    facet_col=None,\n",
      "    facet_col_wrap=0,\n",
      "    facet_row_spacing=None,\n",
      "    facet_col_spacing=None,\n",
      "    error_x=None,\n",
      "    error_x_minus=None,\n",
      "    error_y=None,\n",
      "    error_y_minus=None,\n",
      "    animation_frame=None,\n",
      "    animation_group=None,\n",
      "    category_orders=None,\n",
      "    labels={'epoch': 'Epoch', 'text_selection_method': 'Text selection method', 'train_loss': 'Train Loss'},\n",
      "    orientation=None,\n",
      "    color_discrete_sequence=None,\n",
      "    color_discrete_map=None,\n",
      "    line_dash_sequence=None,\n",
      "    line_dash_map=None,\n",
      "    symbol_sequence=None,\n",
      "    symbol_map=None,\n",
      "    markers=True,\n",
      "    log_x=False,\n",
      "    log_y=False,\n",
      "    range_x=None,\n",
      "    range_y=None,\n",
      "    line_shape=None,\n",
      "    render_mode='auto',\n",
      "    title='Train Loss Over Epochs',\n",
      "    template=None,\n",
      "    width=None,\n",
      "    height=None\n",
      ")\n",
      "    216 def line(\n",
      "    217     data_frame=None,\n",
      "    218     x=None,\n",
      "   (...)\n",
      "    258     height=None,\n",
      "    259 ) -> go.Figure:\n",
      "    260     \"\"\"\n",
      "    261     In a 2D line plot, each row of `data_frame` is represented as vertex of\n",
      "    262     a polyline mark in 2D space.\n",
      "    263     \"\"\"\n",
      "--> 264     return make_figure(args=locals(), constructor=go.Scatter)\n",
      "        go = <module 'plotly.graph_objs' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\plotly\\\\graph_objs\\\\__init__.py'>\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_core.py:2130, in make_figure(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': 'text_selection_method', 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame':       epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'error_x': None, 'error_x_minus': None, ...},\n",
      "    constructor=<class 'plotly.graph_objs._scatter.Scatter'>,\n",
      "    trace_patch={'line': {'shape': None}, 'mode': 'lines+markers'},\n",
      "    layout_patch={}\n",
      ")\n",
      "   2126 trace_specs, grouped_mappings, sizeref, show_colorbar = infer_config(\n",
      "   2127     args, constructor, trace_patch, layout_patch\n",
      "   2128 )\n",
      "   2129 grouper = [x.grouper or one_group for x in grouped_mappings] or [one_group]\n",
      "-> 2130 groups, orders = get_groups_and_orders(args, grouper)\n",
      "        args = {'data_frame':       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'x': 'epoch', 'y': 'train_loss', 'line_group': None, 'color': 'text_selection_method', 'line_dash': None, 'symbol': None, 'hover_name': None, 'hover_data': None, 'custom_data': None, 'text': None, 'facet_row': None, 'facet_col': None, 'facet_col_wrap': 0, 'facet_row_spacing': None, 'facet_col_spacing': None, 'error_x': None, 'error_x_minus': None, 'error_y': None, 'error_y_minus': None, 'animation_frame': None, 'animation_group': None, 'category_orders': None, 'labels': {'epoch': 'Epoch', 'train_loss': 'Train Loss', 'text_selection_method': 'Text selection method'}, 'orientation': None, 'color_discrete_sequence': None, 'color_discrete_map': None, 'line_dash_sequence': None, 'line_dash_map': None, 'symbol_sequence': None, 'symbol_map': None, 'markers': True, 'log_x': False, 'log_y': False, 'range_x': None, 'range_y': None, 'line_shape': None, 'render_mode': 'auto', 'title': 'Train Loss Over Epochs', 'template': None, 'width': None, 'height': None}\n",
      "        grouper = ['text_selection_method', <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>, <function one_group at 0x000002699864CE00>]\n",
      "   2132 col_labels = []\n",
      "   2133 row_labels = []\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\plotly\\express\\_core.py:2064, in get_groups_and_orders(\n",
      "    args={'animation_frame': None, 'animation_group': None, 'category_orders': None, 'color': 'text_selection_method', 'color_discrete_map': None, 'color_discrete_sequence': None, 'custom_data': None, 'data_frame':       epoch  train_loss  train_accuracy  train_f...ive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'error_x': None, 'error_x_minus': None, ...},\n",
      "    grouper=['text_selection_method', <function one_group>, <function one_group>, <function one_group>, <function one_group>, <function one_group>, <function one_group>]\n",
      ")\n",
      "   2062 else:\n",
      "   2063     if col not in unique_cache:\n",
      "-> 2064         unique_cache[col] = list(args[\"data_frame\"][col].unique())\n",
      "        unique_cache = {}\n",
      "        col = 'text_selection_method'\n",
      "        args[\"data_frame\"] =       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns]\n",
      "        args = {'data_frame':       epoch  train_loss  train_accuracy  train_f1  val_loss  val_accuracy  \\\n",
      "0         1    0.062234        0.976605  0.976593  0.080573      0.486755   \n",
      "1         2    0.058572        0.957632  0.957597  0.088242      0.486755   \n",
      "2         3    0.051674        0.960628  0.960592  0.077515      0.486755   \n",
      "3         4    0.058391        0.950642  0.950566  0.110156      0.486755   \n",
      "4         5    0.057500        0.959201  0.959176  0.073136      0.486755   \n",
      "...     ...         ...             ...       ...       ...           ...   \n",
      "1075      6    0.139696        0.883046  0.881622  0.089918      0.500000   \n",
      "1076      7    0.174216        0.831822  0.828276  0.091599      0.500000   \n",
      "1077      8    0.439157        0.649592  0.629888  0.091264      0.498195   \n",
      "1078      9    0.185981        0.840435  0.836961  0.096216      0.500000   \n",
      "1079     10    0.179156        0.839529  0.837606  0.095137      0.500000   \n",
      "\n",
      "        val_f1             ts_encoder_name  ts_encoder_ts_window  \\\n",
      "0     0.318722  TimeSeriesTransformerModel                     6   \n",
      "1     0.318722  TimeSeriesTransformerModel                     6   \n",
      "2     0.318722  TimeSeriesTransformerModel                     6   \n",
      "3     0.318722  TimeSeriesTransformerModel                     6   \n",
      "4     0.318722  TimeSeriesTransformerModel                     6   \n",
      "...        ...                         ...                   ...   \n",
      "1075  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1076  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1077  0.332530  TimeSeriesTransformerModel                     6   \n",
      "1078  0.333333  TimeSeriesTransformerModel                     6   \n",
      "1079  0.333333  TimeSeriesTransformerModel                     6   \n",
      "\n",
      "      ts_encoder_context_length  ...  data_source_name  \\\n",
      "0                             1  ...               EDT   \n",
      "1                             1  ...               EDT   \n",
      "2                             1  ...               EDT   \n",
      "3                             1  ...               EDT   \n",
      "4                             1  ...               EDT   \n",
      "...                         ...  ...               ...   \n",
      "1075                          1  ...         stock_net   \n",
      "1076                          1  ...         stock_net   \n",
      "1077                          1  ...         stock_net   \n",
      "1078                          1  ...         stock_net   \n",
      "1079                          1  ...         stock_net   \n",
      "\n",
      "                          data_source_text_path  \\\n",
      "0                 ./data/EDT/evaluate_news.json   \n",
      "1                 ./data/EDT/evaluate_news.json   \n",
      "2                 ./data/EDT/evaluate_news.json   \n",
      "3                 ./data/EDT/evaluate_news.json   \n",
      "4                 ./data/EDT/evaluate_news.json   \n",
      "...                                         ...   \n",
      "1075  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1076  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1077  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1078  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "1079  ./data/stocknet/tweet/organised_tweet.csv   \n",
      "\n",
      "                data_source_ts_path data_source_ts_date_col  \\\n",
      "0     ./data/EDT/evaluate_news.json                    Date   \n",
      "1     ./data/EDT/evaluate_news.json                    Date   \n",
      "2     ./data/EDT/evaluate_news.json                    Date   \n",
      "3     ./data/EDT/evaluate_news.json                    Date   \n",
      "4     ./data/EDT/evaluate_news.json                    Date   \n",
      "...                             ...                     ...   \n",
      "1075     ./data/stocknet/price/raw/                    Date   \n",
      "1076     ./data/stocknet/price/raw/                    Date   \n",
      "1077     ./data/stocknet/price/raw/                    Date   \n",
      "1078     ./data/stocknet/price/raw/                    Date   \n",
      "1079     ./data/stocknet/price/raw/                    Date   \n",
      "\n",
      "      data_source_text_date_col data_source_text_col  data_source_train_dates  \\\n",
      "0                          date                 text  01/01/2020 - 03/09/2020   \n",
      "1                          date                 text  01/01/2020 - 03/09/2020   \n",
      "2                          date                 text  01/01/2020 - 03/09/2020   \n",
      "3                          date                 text  01/01/2020 - 03/09/2020   \n",
      "4                          date                 text  01/01/2020 - 03/09/2020   \n",
      "...                         ...                  ...                      ...   \n",
      "1075                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1076                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1077                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1078                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "1079                 created_at                 text  01/01/2014 - 01/08/2015   \n",
      "\n",
      "       data_source_test_dates negatives_creation random_state  \n",
      "0     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "1     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "2     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "3     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "4     04/09/2020 - 31/12/2020        [naive, 60]           42  \n",
      "...                       ...                ...          ...  \n",
      "1075  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1076  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1077  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1078  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "1079  01/08/2015 - 01/01/2016        [naive, 60]           44  \n",
      "\n",
      "[1080 rows x 37 columns], 'x': 'epoch', 'y': 'train_loss', 'line_group': None, 'color': 'text_selection_method', 'line_dash': None, 'symbol': None, 'hover_name': None, 'hover_data': None, 'custom_data': None, 'text': None, 'facet_row': None, 'facet_col': None, 'facet_col_wrap': 0, 'facet_row_spacing': None, 'facet_col_spacing': None, 'error_x': None, 'error_x_minus': None, 'error_y': None, 'error_y_minus': None, 'animation_frame': None, 'animation_group': None, 'category_orders': None, 'labels': {'epoch': 'Epoch', 'train_loss': 'Train Loss', 'text_selection_method': 'Text selection method'}, 'orientation': None, 'color_discrete_sequence': None, 'color_discrete_map': None, 'line_dash_sequence': None, 'line_dash_map': None, 'symbol_sequence': None, 'symbol_map': None, 'markers': True, 'log_x': False, 'log_y': False, 'range_x': None, 'range_y': None, 'line_shape': None, 'render_mode': 'auto', 'title': 'Train Loss Over Epochs', 'template': None, 'width': None, 'height': None}\n",
      "   2065     uniques = unique_cache[col]\n",
      "   2066     if len(uniques) == 1:\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\series.py:2407, in Series.unique(\n",
      "    self=0       [TFIDF, 5]\n",
      "1       [TFIDF, 5]\n",
      "2       [T...ext_selection_method, Length: 1080, dtype: object\n",
      ")\n",
      "   2344 def unique(self) -> ArrayLike:  # pylint: disable=useless-parent-delegation\n",
      "   2345     \"\"\"\n",
      "   2346     Return unique values of Series object.\n",
      "   2347 \n",
      "   (...)\n",
      "   2405     Categories (3, object): ['a' < 'b' < 'c']\n",
      "   2406     \"\"\"\n",
      "-> 2407     return super().unique()\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\base.py:1025, in IndexOpsMixin.unique(\n",
      "    self=0       [TFIDF, 5]\n",
      "1       [TFIDF, 5]\n",
      "2       [T...ext_selection_method, Length: 1080, dtype: object\n",
      ")\n",
      "   1023     result = values.unique()\n",
      "   1024 else:\n",
      "-> 1025     result = algorithms.unique1d(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "        algorithms.unique1d = <function unique at 0x00000269FF354860>\n",
      "        algorithms = <module 'pandas.core.algorithms' from 'C:\\\\Users\\\\eoinp\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\pandas\\\\core\\\\algorithms.py'>\n",
      "   1026 return result\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:401, in unique(\n",
      "    values=array([list(['TFIDF', 5]), list(['TFIDF', 5]), l...F', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      ")\n",
      "    307 def unique(values):\n",
      "    308     \"\"\"\n",
      "    309     Return unique values based on a hash table.\n",
      "    310 \n",
      "   (...)\n",
      "    399     array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\n",
      "    400     \"\"\"\n",
      "--> 401     return unique_with_mask(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "\n",
      "File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\algorithms.py:440, in unique_with_mask(\n",
      "    values=array([list(['TFIDF', 5]), list(['TFIDF', 5]), l...F', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object),\n",
      "    mask=None\n",
      ")\n",
      "    438 table = hashtable(len(values))\n",
      "    439 if mask is None:\n",
      "--> 440     uniques = table.unique(values)\n",
      "        values = array([list(['TFIDF', 5]), list(['TFIDF', 5]), list(['TFIDF', 5]), ...,\n",
      "       list(['TFIDF', 2]), list(['TFIDF', 2]), list(['TFIDF', 2])],\n",
      "      dtype=object)\n",
      "        table = <pandas._libs.hashtable.PyObjectHashTable object at 0x000002699EB8FED0>\n",
      "    441     uniques = _reconstruct_data(uniques, original.dtype, original)\n",
      "    442     return uniques\n",
      "\n",
      "File pandas\\\\_libs\\\\hashtable_class_helper.pxi:7248, in pandas._libs.hashtable.PyObjectHashTable.unique()\n",
      "\n",
      "File pandas\\\\_libs\\\\hashtable_class_helper.pxi:7195, in pandas._libs.hashtable.PyObjectHashTable._unique()\n",
      "\n",
      "TypeError: unhashable type: 'list'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"./results/part_selection_results.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Function to flatten nested dictionary (dataset_params and model_params)\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Function to process the JSON data into a DataFrame\n",
    "def process_data(data):\n",
    "    rows = []\n",
    "    for entry in data:\n",
    "        # Flatten model_params and dataset_params and combine them\n",
    "        flattened_params = {**flatten_dict(entry[\"model_params\"]), **flatten_dict(entry[\"dataset_params\"])}\n",
    "        \n",
    "        # Add train and validation metrics\n",
    "        train_metrics = entry[\"train_metrics\"]\n",
    "        val_metrics = entry[\"val_metrics\"]\n",
    "\n",
    "        for epoch in range(entry[\"epochs\"]):\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_metrics['loss'][epoch],\n",
    "                'train_accuracy': train_metrics['accuracy'][epoch],\n",
    "                'train_f1': train_metrics['f1'][epoch],\n",
    "                'val_loss': val_metrics['loss'][epoch],\n",
    "                'val_accuracy': val_metrics['accuracy'][epoch],\n",
    "                'val_f1': val_metrics['f1'][epoch],\n",
    "            }\n",
    "            row.update(flattened_params)  # Include all flattened parameters in the row\n",
    "            rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Convert the JSON data to a DataFrame\n",
    "df = process_data(data)\n",
    "\n",
    "# Get all unique parameter names (excluding metric columns)\n",
    "pivot_options = [col for col in df.columns if col not in ['epoch', 'train_loss', 'train_accuracy', 'train_f1', 'val_loss', 'val_accuracy', 'val_f1']]\n",
    "\n",
    "# Create a Dash app for interactive plotting\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Model Training Metrics\"),\n",
    "    \n",
    "    # Dropdown for selecting the metric to display\n",
    "    html.Label(\"Choose a Metric:\"),\n",
    "    dcc.Dropdown(\n",
    "        id=\"metric\",\n",
    "        options=[\n",
    "            {'label': 'Loss', 'value': 'loss'},\n",
    "            {'label': 'Accuracy', 'value': 'accuracy'},\n",
    "            {'label': 'F1 Score', 'value': 'f1'},\n",
    "        ],\n",
    "        value='loss'\n",
    "    ),\n",
    "    \n",
    "    # Dropdown for selecting the hyperparameter to pivot over (dynamic based on dataset)\n",
    "    html.Label(\"Choose a Hyperparameter to Pivot Over:\"),\n",
    "    dcc.Dropdown(\n",
    "        id=\"pivot_by\",\n",
    "        options=[{'label': col.replace('_', ' ').capitalize(), 'value': col} for col in pivot_options],\n",
    "        value='learning_rate'\n",
    "    ),\n",
    "\n",
    "    # Toggle to switch between individual performance and summary view\n",
    "    dcc.RadioItems(\n",
    "        id='view_mode',\n",
    "        options=[\n",
    "            {'label': 'Individual', 'value': 'individual'},\n",
    "            {'label': 'Summary', 'value': 'summary'}\n",
    "        ],\n",
    "        value='individual',\n",
    "        labelStyle={'display': 'inline-block'}\n",
    "    ),\n",
    "    \n",
    "    # Plot for training metrics\n",
    "    dcc.Graph(id='train_metric_graph'),\n",
    "    \n",
    "    # Plot for validation metrics\n",
    "    dcc.Graph(id='val_metric_graph')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('train_metric_graph', 'figure'),\n",
    "     Output('val_metric_graph', 'figure')],\n",
    "    [Input('metric', 'value'),\n",
    "     Input('pivot_by', 'value'),\n",
    "     Input('view_mode', 'value')]\n",
    ")\n",
    "def update_graph(selected_metric, pivot_by, view_mode):\n",
    "    train_metric_col = f\"train_{selected_metric}\"\n",
    "    val_metric_col = f\"val_{selected_metric}\"\n",
    "\n",
    "    if view_mode == 'summary':\n",
    "        summary_df = df.groupby(['epoch', pivot_by]).agg(\n",
    "            min_train_metric=(train_metric_col, 'min'),\n",
    "            min_val_metric=(val_metric_col, 'min'),\n",
    "        ).reset_index()\n",
    "\n",
    "        # Prepare figure for training metrics\n",
    "        train_fig = go.Figure()\n",
    "\n",
    "        unique_pivot_vals = summary_df[pivot_by].unique()\n",
    "        color_map = px.colors.qualitative.Plotly[:len(unique_pivot_vals)]\n",
    "\n",
    "        for i, val in enumerate(unique_pivot_vals):\n",
    "            pivot_group = summary_df[summary_df[pivot_by] == val]\n",
    "\n",
    "            train_fig.add_trace(go.Scatter(\n",
    "                x=pivot_group['epoch'],\n",
    "                y=pivot_group['min_train_metric'],\n",
    "                mode='lines',\n",
    "                name=f'Min Train ({val})',\n",
    "                line=dict(color=color_map[i], dash='dash')\n",
    "            ))\n",
    "\n",
    "        train_fig.update_layout(\n",
    "            title=f\"Train {selected_metric.capitalize()} Summary Over Epochs\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=f\"Train {selected_metric.capitalize()}\"\n",
    "        )\n",
    "\n",
    "        # Prepare figure for validation metrics\n",
    "        val_fig = go.Figure()\n",
    "\n",
    "        for i, val in enumerate(unique_pivot_vals):\n",
    "            pivot_group = summary_df[summary_df[pivot_by] == val]\n",
    "\n",
    "            val_fig.add_trace(go.Scatter(\n",
    "                x=pivot_group['epoch'],\n",
    "                y=pivot_group['min_val_metric'],\n",
    "                mode='lines',\n",
    "                name=f'Min Val ({val})',\n",
    "                line=dict(color=color_map[i], dash='dash')\n",
    "            ))\n",
    "\n",
    "        val_fig.update_layout(\n",
    "            title=f\"Validation {selected_metric.capitalize()} Summary Over Epochs\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=f\"Validation {selected_metric.capitalize()}\"\n",
    "        )\n",
    "\n",
    "    else:  # Individual mode\n",
    "        # Plot for training metrics (individual performance)\n",
    "        train_fig = px.line(df, x=\"epoch\", y=train_metric_col, color=pivot_by, markers=True,\n",
    "                            labels={\n",
    "                                \"epoch\": \"Epoch\",\n",
    "                                train_metric_col: f\"Train {selected_metric.capitalize()}\",\n",
    "                                pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
    "                            },\n",
    "                            title=f\"Train {selected_metric.capitalize()} Over Epochs\")\n",
    "        \n",
    "        # Plot for validation metrics (individual performance)\n",
    "        val_fig = px.line(df, x=\"epoch\", y=val_metric_col, color=pivot_by, markers=True,\n",
    "                          labels={\n",
    "                              \"epoch\": \"Epoch\",\n",
    "                              val_metric_col: f\"Validation {selected_metric.capitalize()}\",\n",
    "                              pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
    "                          },\n",
    "                          title=f\"Validation {selected_metric.capitalize()} Over Epochs\")\n",
    "\n",
    "    return train_fig, val_fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "print(1 * 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-5 == 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2699eb339e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"./output_final_plotting.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Function to flatten nested dictionary (dataset_params and model_params)\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Function to process the JSON data into a DataFrame\n",
    "def process_data(data):\n",
    "    rows = []\n",
    "    for entry in data:\n",
    "        # Flatten model_params and dataset_params and combine them\n",
    "        flattened_params = {**flatten_dict(entry[\"model_params\"]), **flatten_dict(entry[\"dataset_params\"])}\n",
    "        \n",
    "        # Add train and validation metrics\n",
    "        train_metrics = entry[\"train_metrics\"]\n",
    "        val_metrics = entry[\"val_metrics\"]\n",
    "\n",
    "        for epoch in range(entry[\"epochs\"]):\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_metrics['loss'][epoch],\n",
    "                'train_accuracy': train_metrics['accuracy'][epoch],\n",
    "                'train_f1': train_metrics['f1'][epoch],\n",
    "                'val_loss': val_metrics['loss'][epoch],\n",
    "                'val_accuracy': val_metrics['accuracy'][epoch],\n",
    "                'val_f1': val_metrics['f1'][epoch],\n",
    "            }\n",
    "            row.update(flattened_params)  # Include all flattened parameters in the row\n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    # Convert unhashable types (lists, dictionaries, etc.) into strings for pivoting\n",
    "    for col in df.columns:\n",
    "        if df[col].apply(lambda x: isinstance(x, (list, dict, tuple))).any():\n",
    "            df[col] = df[col].apply(lambda x: str(x))  # Convert to string\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Convert the JSON data to a DataFrame\n",
    "df = process_data(data)\n",
    "\n",
    "# Get all unique parameter names (excluding metric columns)\n",
    "pivot_options = [col for col in df.columns if col not in ['epoch', 'train_loss', 'train_accuracy', 'train_f1', 'val_loss', 'val_accuracy', 'val_f1']]\n",
    "\n",
    "# Create a Dash app for interactive plotting\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Model Training Metrics\"),\n",
    "    \n",
    "    # Dropdown for selecting the metric to display\n",
    "    html.Label(\"Choose a Metric:\"),\n",
    "    dcc.Dropdown(\n",
    "        id=\"metric\",\n",
    "        options=[\n",
    "            {'label': 'Loss', 'value': 'loss'},\n",
    "            {'label': 'Accuracy', 'value': 'accuracy'},\n",
    "            {'label': 'F1 Score', 'value': 'f1'},\n",
    "        ],\n",
    "        value='loss'\n",
    "    ),\n",
    "    \n",
    "    # Dropdown for selecting the hyperparameter to pivot over (dynamic based on dataset)\n",
    "    html.Label(\"Choose a Hyperparameter to Pivot Over:\"),\n",
    "    dcc.Dropdown(\n",
    "        id=\"pivot_by\",\n",
    "        options=[{'label': str(col).replace('_', ' ').capitalize(), 'value': str(col)} for col in pivot_options],\n",
    "        value='learning_rate'\n",
    "    ),\n",
    "\n",
    "    # Toggle to switch between individual, summary, and comparison view\n",
    "    dcc.RadioItems(\n",
    "        id='view_mode',\n",
    "        options=[\n",
    "            {'label': 'Individual', 'value': 'individual'},\n",
    "            {'label': 'Summary', 'value': 'summary'},\n",
    "            {'label': 'Comparison', 'value': 'comparison'}\n",
    "        ],\n",
    "        value='individual',\n",
    "        labelStyle={'display': 'inline-block'}\n",
    "    ),\n",
    "    \n",
    "    # Plot for training metrics\n",
    "    dcc.Graph(id='train_metric_graph'),\n",
    "    \n",
    "    # Plot for validation metrics\n",
    "    dcc.Graph(id='val_metric_graph')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('train_metric_graph', 'figure'),\n",
    "     Output('val_metric_graph', 'figure')],\n",
    "    [Input('metric', 'value'),\n",
    "     Input('pivot_by', 'value'),\n",
    "     Input('view_mode', 'value')]\n",
    ")\n",
    "def update_graph(selected_metric, pivot_by, view_mode):\n",
    "    train_metric_col = f\"train_{selected_metric}\"\n",
    "    val_metric_col = f\"val_{selected_metric}\"\n",
    "\n",
    "    if view_mode == 'summary':\n",
    "        summary_df = df.groupby(['epoch', pivot_by]).agg(\n",
    "            min_train_metric=(train_metric_col, 'min'),\n",
    "            min_val_metric=(val_metric_col, 'min'),\n",
    "        ).reset_index()\n",
    "\n",
    "        # Prepare figure for training metrics\n",
    "        train_fig = go.Figure()\n",
    "\n",
    "        unique_pivot_vals = summary_df[pivot_by].unique()\n",
    "        color_map = px.colors.qualitative.Plotly[:len(unique_pivot_vals)]\n",
    "\n",
    "        for i, val in enumerate(unique_pivot_vals):\n",
    "            pivot_group = summary_df[summary_df[pivot_by] == val]\n",
    "\n",
    "            train_fig.add_trace(go.Scatter(\n",
    "                x=pivot_group['epoch'],\n",
    "                y=pivot_group['min_train_metric'],\n",
    "                mode='lines',\n",
    "                name=f'Min Train ({val})',\n",
    "                line=dict(color=color_map[i], dash='dash')\n",
    "            ))\n",
    "\n",
    "        train_fig.update_layout(\n",
    "            title=f\"Train {selected_metric.capitalize()} Summary Over Epochs\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=f\"Train {selected_metric.capitalize()}\"\n",
    "        )\n",
    "\n",
    "        # Prepare figure for validation metrics\n",
    "        val_fig = go.Figure()\n",
    "\n",
    "        for i, val in enumerate(unique_pivot_vals):\n",
    "            pivot_group = summary_df[summary_df[pivot_by] == val]\n",
    "\n",
    "            val_fig.add_trace(go.Scatter(\n",
    "                x=pivot_group['epoch'],\n",
    "                y=pivot_group['min_val_metric'],\n",
    "                mode='lines',\n",
    "                name=f'Min Val ({val})',\n",
    "                line=dict(color=color_map[i], dash='dash')\n",
    "            ))\n",
    "\n",
    "        val_fig.update_layout(\n",
    "            title=f\"Validation {selected_metric.capitalize()} Summary Over Epochs\",\n",
    "            xaxis_title=\"Epoch\",\n",
    "            yaxis_title=f\"Validation {selected_metric.capitalize()}\"\n",
    "        )\n",
    "\n",
    "    elif view_mode == 'comparison':\n",
    "        # Exclude columns that contain lists or unhashable types\n",
    "        comparison_cols = [col for col in df.columns if col not in ['epoch', train_metric_col, val_metric_col, pivot_by] and not isinstance(df[col].iloc[0], list)]\n",
    "\n",
    "        # Filter out cases where only the pivot_by value differs\n",
    "        comparison_df = df.groupby(comparison_cols).filter(lambda x: x[pivot_by].nunique() > 1)\n",
    "\n",
    "        train_fig = px.line(comparison_df, x=\"epoch\", y=train_metric_col, color=pivot_by, markers=True,\n",
    "                            labels={\n",
    "                                \"epoch\": \"Epoch\",\n",
    "                                train_metric_col: f\"Train {selected_metric.capitalize()}\",\n",
    "                                pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
    "                            },\n",
    "                            title=f\"Train {selected_metric.capitalize()} Comparison Over Epochs\")\n",
    "        \n",
    "        val_fig = px.line(comparison_df, x=\"epoch\", y=val_metric_col, color=pivot_by, markers=True,\n",
    "                        labels={\n",
    "                            \"epoch\": \"Epoch\",\n",
    "                            val_metric_col: f\"Validation {selected_metric.capitalize()}\",\n",
    "                            pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
    "                        },\n",
    "                        title=f\"Validation {selected_metric.capitalize()} Comparison Over Epochs\")\n",
    "\n",
    "\n",
    "    else:  # Individual mode\n",
    "        # Plot for training metrics (individual performance)\n",
    "        train_fig = px.line(df, x=\"epoch\", y=train_metric_col, color=pivot_by, markers=True,\n",
    "                            labels={\n",
    "                                \"epoch\": \"Epoch\",\n",
    "                                train_metric_col: f\"Train {selected_metric.capitalize()}\",\n",
    "                                pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
    "                            },\n",
    "                            title=f\"Train {selected_metric.capitalize()} Over Epochs\")\n",
    "        \n",
    "        # Plot for validation metrics (individual performance)\n",
    "        val_fig = px.line(df, x=\"epoch\", y=val_metric_col, color=pivot_by, markers=True,\n",
    "                          labels={\n",
    "                              \"epoch\": \"Epoch\",\n",
    "                              val_metric_col: f\"Validation {selected_metric.capitalize()}\",\n",
    "                              pivot_by: pivot_by.replace(\"_\", \" \").capitalize()\n",
    "                          },\n",
    "                          title=f\"Validation {selected_metric.capitalize()} Over Epochs\")\n",
    "\n",
    "    return train_fig, val_fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
