{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for analysing and reviewing experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 1165)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m target_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(target_file)\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 1165)"
     ]
    }
   ],
   "source": [
    "target_file = \"output.json\"\n",
    "f = open(target_file)\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Prior to Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import model_helper as mh\n",
    "import data_helper_v2 as dh\n",
    "\n",
    "model = mh.get_model(ts_encoder_config={\"name\": 'LSTM'}, text_encoder_config={\"name\": 'bert-base-uncased', \"auto-pre-trained\": True},\n",
    "                      projection_dim=64, ts_window=5)\n",
    "    \n",
    "df = dh._helper_generate_synthetic_benchmark(model=model)\n",
    "\n",
    "df[\"label\"] = df['label'].replace(0, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [01:16<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "df[\"cosine_similarity\"] = None\n",
    "\n",
    "\n",
    "text_tokenizer = model.get_text_tokenizer()\n",
    "prior_to_train_dataset = dh.CustomDataset(df, text_tokenizer=text_tokenizer)\n",
    "\n",
    "dataloader = DataLoader(prior_to_train_dataset, batch_size=32, shuffle=False)\n",
    "device = 'cpu'\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ts_data, text_data, attention_mask, labels in tqdm(dataloader, leave=True, position=1):\n",
    "        ts_data = ts_data.to(device)\n",
    "        text_data = text_data.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ts_embeddings, text_embeddings = model(ts_data, text_data, attention_mask)\n",
    "\n",
    "\n",
    "\n",
    "        preds = model.predict(ts_data=ts_data, input_ids=text_data, attention_mask=attention_mask)#TODO same as train loop, check it works with the batch of embeddings\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "all_preds = np.array(all_preds) #convert to numpy array\n",
    "df[\"cosine_similarity\"] = all_preds\n",
    "\n",
    "df_positives = df.loc[df[\"label\"] == 1]\n",
    "df_negatives = df.loc[df[\"label\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>text</th>\n",
       "      <th>time_series</th>\n",
       "      <th>label</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-14 23:13:20.863736</td>\n",
       "      <td>decline decrease drop negative loss</td>\n",
       "      <td>[[51], [50], [49], [48], [47]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-12 23:13:20.863736</td>\n",
       "      <td>negative decrease drop loss decline</td>\n",
       "      <td>[[78], [77], [76], [75], [74]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-11 23:13:20.863736</td>\n",
       "      <td>growth positive gain rise increase</td>\n",
       "      <td>[[67], [68], [69], [70], [71]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-09 23:13:20.863736</td>\n",
       "      <td>drop decrease decline negative loss</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.071609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-08 23:13:20.863736</td>\n",
       "      <td>positive gain growth increase rise</td>\n",
       "      <td>[[75], [76], [77], [78], [79]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.102501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>2991</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-11 23:13:20.863736</td>\n",
       "      <td>gain growth rise increase positive</td>\n",
       "      <td>[[82], [83], [84], [85], [86]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.101563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>2994</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-08 23:13:20.863736</td>\n",
       "      <td>decline decrease negative loss drop</td>\n",
       "      <td>[[97], [96], [95], [94], [93]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.081359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2995</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-07 23:13:20.863736</td>\n",
       "      <td>rise positive increase growth gain</td>\n",
       "      <td>[[88], [89], [90], [91], [92]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.088990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2996</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-06 23:13:20.863736</td>\n",
       "      <td>positive gain growth increase rise</td>\n",
       "      <td>[[91], [92], [93], [94], [95]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2999</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-03 23:13:20.863736</td>\n",
       "      <td>negative decrease decline loss drop</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.087570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id ticker                 Start Date  \\\n",
       "0        0   APPL 2024-08-14 23:13:20.863736   \n",
       "2        2   APPL 2024-08-12 23:13:20.863736   \n",
       "3        3   APPL 2024-08-11 23:13:20.863736   \n",
       "5        5   APPL 2024-08-09 23:13:20.863736   \n",
       "6        6   APPL 2024-08-08 23:13:20.863736   \n",
       "...    ...    ...                        ...   \n",
       "2991  2991   MSFN 2023-04-11 23:13:20.863736   \n",
       "2994  2994   MSFN 2023-04-08 23:13:20.863736   \n",
       "2995  2995   MSFN 2023-04-07 23:13:20.863736   \n",
       "2996  2996   MSFN 2023-04-06 23:13:20.863736   \n",
       "2999  2999   MSFN 2023-04-03 23:13:20.863736   \n",
       "\n",
       "                                     text                     time_series  \\\n",
       "0     decline decrease drop negative loss  [[51], [50], [49], [48], [47]]   \n",
       "2     negative decrease drop loss decline  [[78], [77], [76], [75], [74]]   \n",
       "3      growth positive gain rise increase  [[67], [68], [69], [70], [71]]   \n",
       "5     drop decrease decline negative loss  [[57], [56], [55], [54], [53]]   \n",
       "6      positive gain growth increase rise  [[75], [76], [77], [78], [79]]   \n",
       "...                                   ...                             ...   \n",
       "2991   gain growth rise increase positive  [[82], [83], [84], [85], [86]]   \n",
       "2994  decline decrease negative loss drop  [[97], [96], [95], [94], [93]]   \n",
       "2995   rise positive increase growth gain  [[88], [89], [90], [91], [92]]   \n",
       "2996   positive gain growth increase rise  [[91], [92], [93], [94], [95]]   \n",
       "2999  negative decrease decline loss drop  [[57], [56], [55], [54], [53]]   \n",
       "\n",
       "      label  cosine_similarity  \n",
       "0         1          -0.047213  \n",
       "2         1          -0.125635  \n",
       "3         1          -0.108888  \n",
       "5         1          -0.071609  \n",
       "6         1          -0.102501  \n",
       "...     ...                ...  \n",
       "2991      1          -0.101563  \n",
       "2994      1          -0.081359  \n",
       "2995      1          -0.088990  \n",
       "2996      1          -0.107800  \n",
       "2999      1          -0.087570  \n",
       "\n",
       "[1518 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>text</th>\n",
       "      <th>time_series</th>\n",
       "      <th>label</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-14 23:13:20.863736</td>\n",
       "      <td>decline decrease drop negative loss</td>\n",
       "      <td>[[51], [50], [49], [48], [47]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-12 23:13:20.863736</td>\n",
       "      <td>negative decrease drop loss decline</td>\n",
       "      <td>[[78], [77], [76], [75], [74]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.125635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-11 23:13:20.863736</td>\n",
       "      <td>growth positive gain rise increase</td>\n",
       "      <td>[[67], [68], [69], [70], [71]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-09 23:13:20.863736</td>\n",
       "      <td>drop decrease decline negative loss</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.071609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-08 23:13:20.863736</td>\n",
       "      <td>positive gain growth increase rise</td>\n",
       "      <td>[[75], [76], [77], [78], [79]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.102501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>2991</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-11 23:13:20.863736</td>\n",
       "      <td>gain growth rise increase positive</td>\n",
       "      <td>[[82], [83], [84], [85], [86]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.101563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>2994</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-08 23:13:20.863736</td>\n",
       "      <td>decline decrease negative loss drop</td>\n",
       "      <td>[[97], [96], [95], [94], [93]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.081359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2995</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-07 23:13:20.863736</td>\n",
       "      <td>rise positive increase growth gain</td>\n",
       "      <td>[[88], [89], [90], [91], [92]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.088990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2996</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-06 23:13:20.863736</td>\n",
       "      <td>positive gain growth increase rise</td>\n",
       "      <td>[[91], [92], [93], [94], [95]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2999</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-03 23:13:20.863736</td>\n",
       "      <td>negative decrease decline loss drop</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.087570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id ticker                 Start Date  \\\n",
       "0        0   APPL 2024-08-14 23:13:20.863736   \n",
       "2        2   APPL 2024-08-12 23:13:20.863736   \n",
       "3        3   APPL 2024-08-11 23:13:20.863736   \n",
       "5        5   APPL 2024-08-09 23:13:20.863736   \n",
       "6        6   APPL 2024-08-08 23:13:20.863736   \n",
       "...    ...    ...                        ...   \n",
       "2991  2991   MSFN 2023-04-11 23:13:20.863736   \n",
       "2994  2994   MSFN 2023-04-08 23:13:20.863736   \n",
       "2995  2995   MSFN 2023-04-07 23:13:20.863736   \n",
       "2996  2996   MSFN 2023-04-06 23:13:20.863736   \n",
       "2999  2999   MSFN 2023-04-03 23:13:20.863736   \n",
       "\n",
       "                                     text                     time_series  \\\n",
       "0     decline decrease drop negative loss  [[51], [50], [49], [48], [47]]   \n",
       "2     negative decrease drop loss decline  [[78], [77], [76], [75], [74]]   \n",
       "3      growth positive gain rise increase  [[67], [68], [69], [70], [71]]   \n",
       "5     drop decrease decline negative loss  [[57], [56], [55], [54], [53]]   \n",
       "6      positive gain growth increase rise  [[75], [76], [77], [78], [79]]   \n",
       "...                                   ...                             ...   \n",
       "2991   gain growth rise increase positive  [[82], [83], [84], [85], [86]]   \n",
       "2994  decline decrease negative loss drop  [[97], [96], [95], [94], [93]]   \n",
       "2995   rise positive increase growth gain  [[88], [89], [90], [91], [92]]   \n",
       "2996   positive gain growth increase rise  [[91], [92], [93], [94], [95]]   \n",
       "2999  negative decrease decline loss drop  [[57], [56], [55], [54], [53]]   \n",
       "\n",
       "      label  cosine_similarity  \n",
       "0         1          -0.047213  \n",
       "2         1          -0.125635  \n",
       "3         1          -0.108888  \n",
       "5         1          -0.071609  \n",
       "6         1          -0.102501  \n",
       "...     ...                ...  \n",
       "2991      1          -0.101563  \n",
       "2994      1          -0.081359  \n",
       "2995      1          -0.088990  \n",
       "2996      1          -0.107800  \n",
       "2999      1          -0.087570  \n",
       "\n",
       "[1518 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the column you want to plot\n",
    "df_positives['cosine_similarity'].plot(kind='hist', bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of cosine_similarities for positive pairs before fine tuning')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "df_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>text</th>\n",
       "      <th>time_series</th>\n",
       "      <th>label</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-13 23:13:20.863736</td>\n",
       "      <td>decline loss decrease negative drop</td>\n",
       "      <td>[[53], [54], [55], [56], [57]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.088750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-10 23:13:20.863736</td>\n",
       "      <td>loss decrease decline negative drop</td>\n",
       "      <td>[[76], [77], [78], [79], [80]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.063986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-07 23:13:20.863736</td>\n",
       "      <td>decrease drop negative loss decline</td>\n",
       "      <td>[[66], [67], [68], [69], [70]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.102987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-06 23:13:20.863736</td>\n",
       "      <td>decline decrease loss negative drop</td>\n",
       "      <td>[[87], [88], [89], [90], [91]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.074792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-05 23:13:20.863736</td>\n",
       "      <td>gain rise growth increase positive</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.079814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2989</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-13 23:13:20.863736</td>\n",
       "      <td>growth increase positive gain rise</td>\n",
       "      <td>[[67], [66], [65], [64], [63]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.089677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>2992</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-10 23:13:20.863736</td>\n",
       "      <td>negative loss decline decrease drop</td>\n",
       "      <td>[[91], [92], [93], [94], [95]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.103863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>2993</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-09 23:13:20.863736</td>\n",
       "      <td>positive growth increase gain rise</td>\n",
       "      <td>[[93], [92], [91], [90], [89]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.115689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2997</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-05 23:13:20.863736</td>\n",
       "      <td>gain positive increase growth rise</td>\n",
       "      <td>[[86], [85], [84], [83], [82]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.082992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2998</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-04 23:13:20.863736</td>\n",
       "      <td>rise increase positive growth gain</td>\n",
       "      <td>[[99], [98], [97], [96], [95]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.093380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id ticker                 Start Date  \\\n",
       "1        1   APPL 2024-08-13 23:13:20.863736   \n",
       "4        4   APPL 2024-08-10 23:13:20.863736   \n",
       "7        7   APPL 2024-08-07 23:13:20.863736   \n",
       "8        8   APPL 2024-08-06 23:13:20.863736   \n",
       "9        9   APPL 2024-08-05 23:13:20.863736   \n",
       "...    ...    ...                        ...   \n",
       "2989  2989   MSFN 2023-04-13 23:13:20.863736   \n",
       "2992  2992   MSFN 2023-04-10 23:13:20.863736   \n",
       "2993  2993   MSFN 2023-04-09 23:13:20.863736   \n",
       "2997  2997   MSFN 2023-04-05 23:13:20.863736   \n",
       "2998  2998   MSFN 2023-04-04 23:13:20.863736   \n",
       "\n",
       "                                     text                     time_series  \\\n",
       "1     decline loss decrease negative drop  [[53], [54], [55], [56], [57]]   \n",
       "4     loss decrease decline negative drop  [[76], [77], [78], [79], [80]]   \n",
       "7     decrease drop negative loss decline  [[66], [67], [68], [69], [70]]   \n",
       "8     decline decrease loss negative drop  [[87], [88], [89], [90], [91]]   \n",
       "9      gain rise growth increase positive  [[57], [56], [55], [54], [53]]   \n",
       "...                                   ...                             ...   \n",
       "2989   growth increase positive gain rise  [[67], [66], [65], [64], [63]]   \n",
       "2992  negative loss decline decrease drop  [[91], [92], [93], [94], [95]]   \n",
       "2993   positive growth increase gain rise  [[93], [92], [91], [90], [89]]   \n",
       "2997   gain positive increase growth rise  [[86], [85], [84], [83], [82]]   \n",
       "2998   rise increase positive growth gain  [[99], [98], [97], [96], [95]]   \n",
       "\n",
       "      label  cosine_similarity  \n",
       "1        -1          -0.088750  \n",
       "4        -1          -0.063986  \n",
       "7        -1          -0.102987  \n",
       "8        -1          -0.074792  \n",
       "9        -1          -0.079814  \n",
       "...     ...                ...  \n",
       "2989     -1          -0.089677  \n",
       "2992     -1          -0.103863  \n",
       "2993     -1          -0.115689  \n",
       "2997     -1          -0.082992  \n",
       "2998     -1          -0.093380  \n",
       "\n",
       "[1482 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negatives['cosine_similarity'].plot(kind='hist', bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of cosine_similarities for negative pairs before fine tuning')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "df_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [08:48<00:00,  5.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5110882961369575,\n",
       " 0.5086666666666667,\n",
       " 0.38307414889032537,\n",
       " array([[  79, 1403],\n",
       "        [  71, 1447]], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')\n",
    "mh.train(model=model, train_loader=dataloader, optimizer=optimizer , device='cpu', criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 16/94 [00:22<01:49,  1.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 18\u001b[0m\n\u001b[0;32m     12\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m         ts_embeddings, text_embeddings \u001b[38;5;241m=\u001b[39m model(ts_data, text_data, attention_mask)\n\u001b[1;32m---> 18\u001b[0m         preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#TODO same as train loop, check it works with the batch of embeddings\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         after_one_epoch_all_preds\u001b[38;5;241m.\u001b[39mextend(preds)\n\u001b[0;32m     21\u001b[0m after_one_epoch_all_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(after_one_epoch_all_preds) \u001b[38;5;66;03m#convert to numpy array\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\Desktop\\University\\Honours\\implementation\\honours-fin-sentiment\\model_helper.py:85\u001b[0m, in \u001b[0;36mContrastiveLearningModel.predict\u001b[1;34m(self, ts_data, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, ts_data, input_ids, attention_mask):\n\u001b[1;32m---> 85\u001b[0m     ts_embeddings, text_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     ts_embeddings \u001b[38;5;241m=\u001b[39m ts_embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     87\u001b[0m     text_embeddings \u001b[38;5;241m=\u001b[39m text_embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\Desktop\\University\\Honours\\implementation\\honours-fin-sentiment\\model_helper.py:77\u001b[0m, in \u001b[0;36mContrastiveLearningModel.forward\u001b[1;34m(self, ts_data, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ts_data, input_ids, attention_mask):\n\u001b[0;32m     76\u001b[0m     ts_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts_encoder(ts_data)\n\u001b[1;32m---> 77\u001b[0m     text_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     projected_ts_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts_projection_head(ts_embeddings)\n\u001b[0;32m     80\u001b[0m     projected_text_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_projection_head(text_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\Desktop\\University\\Honours\\implementation\\honours-fin-sentiment\\model_helper.py:51\u001b[0m, in \u001b[0;36mTextEncoder.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    979\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    981\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    982\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    983\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    987\u001b[0m )\n\u001b[1;32m--> 988\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    572\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    573\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         output_attentions,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    462\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    394\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:261\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    253\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    260\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 261\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#df[\"cosine_similarity\"] = None\n",
    "\n",
    "model.eval()\n",
    "\n",
    "after_one_epoch_all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ts_data, text_data, attention_mask, labels in tqdm(dataloader, leave=True, position=1):\n",
    "        ts_data = ts_data.to(device)\n",
    "        text_data = text_data.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ts_embeddings, text_embeddings = model(ts_data, text_data, attention_mask)\n",
    "\n",
    "\n",
    "\n",
    "        preds = model.predict(ts_data=ts_data, input_ids=text_data, attention_mask=attention_mask)#TODO same as train loop, check it works with the batch of embeddings\n",
    "        after_one_epoch_all_preds.extend(preds)\n",
    "\n",
    "after_one_epoch_all_preds = np.array(after_one_epoch_all_preds) #convert to numpy array\n",
    "df[\"cosine_similarity\"] = after_one_epoch_all_preds\n",
    "\n",
    "after_one_epoch_all_preds_df_positives = df.loc[df[\"label\"] == 1]\n",
    "after_one_epoch_all_preds_df_negatives = df.loc[df[\"label\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>text</th>\n",
       "      <th>time_series</th>\n",
       "      <th>label</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-13 23:13:20.863736</td>\n",
       "      <td>decline loss decrease negative drop</td>\n",
       "      <td>[[53], [54], [55], [56], [57]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.980636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-10 23:13:20.863736</td>\n",
       "      <td>loss decrease decline negative drop</td>\n",
       "      <td>[[76], [77], [78], [79], [80]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.953558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-07 23:13:20.863736</td>\n",
       "      <td>decrease drop negative loss decline</td>\n",
       "      <td>[[66], [67], [68], [69], [70]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.969306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-06 23:13:20.863736</td>\n",
       "      <td>decline decrease loss negative drop</td>\n",
       "      <td>[[87], [88], [89], [90], [91]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.938658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-05 23:13:20.863736</td>\n",
       "      <td>gain rise growth increase positive</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.979164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2989</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-13 23:13:20.863736</td>\n",
       "      <td>growth increase positive gain rise</td>\n",
       "      <td>[[67], [66], [65], [64], [63]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.975608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>2992</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-10 23:13:20.863736</td>\n",
       "      <td>negative loss decline decrease drop</td>\n",
       "      <td>[[91], [92], [93], [94], [95]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.933957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>2993</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-09 23:13:20.863736</td>\n",
       "      <td>positive growth increase gain rise</td>\n",
       "      <td>[[93], [92], [91], [90], [89]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.938822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2997</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-05 23:13:20.863736</td>\n",
       "      <td>gain positive increase growth rise</td>\n",
       "      <td>[[86], [85], [84], [83], [82]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.947751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2998</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-04 23:13:20.863736</td>\n",
       "      <td>rise increase positive growth gain</td>\n",
       "      <td>[[99], [98], [97], [96], [95]]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.931953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1482 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id ticker                 Start Date  \\\n",
       "1        1   APPL 2024-08-13 23:13:20.863736   \n",
       "4        4   APPL 2024-08-10 23:13:20.863736   \n",
       "7        7   APPL 2024-08-07 23:13:20.863736   \n",
       "8        8   APPL 2024-08-06 23:13:20.863736   \n",
       "9        9   APPL 2024-08-05 23:13:20.863736   \n",
       "...    ...    ...                        ...   \n",
       "2989  2989   MSFN 2023-04-13 23:13:20.863736   \n",
       "2992  2992   MSFN 2023-04-10 23:13:20.863736   \n",
       "2993  2993   MSFN 2023-04-09 23:13:20.863736   \n",
       "2997  2997   MSFN 2023-04-05 23:13:20.863736   \n",
       "2998  2998   MSFN 2023-04-04 23:13:20.863736   \n",
       "\n",
       "                                     text                     time_series  \\\n",
       "1     decline loss decrease negative drop  [[53], [54], [55], [56], [57]]   \n",
       "4     loss decrease decline negative drop  [[76], [77], [78], [79], [80]]   \n",
       "7     decrease drop negative loss decline  [[66], [67], [68], [69], [70]]   \n",
       "8     decline decrease loss negative drop  [[87], [88], [89], [90], [91]]   \n",
       "9      gain rise growth increase positive  [[57], [56], [55], [54], [53]]   \n",
       "...                                   ...                             ...   \n",
       "2989   growth increase positive gain rise  [[67], [66], [65], [64], [63]]   \n",
       "2992  negative loss decline decrease drop  [[91], [92], [93], [94], [95]]   \n",
       "2993   positive growth increase gain rise  [[93], [92], [91], [90], [89]]   \n",
       "2997   gain positive increase growth rise  [[86], [85], [84], [83], [82]]   \n",
       "2998   rise increase positive growth gain  [[99], [98], [97], [96], [95]]   \n",
       "\n",
       "      label  cosine_similarity  \n",
       "1        -1           0.980636  \n",
       "4        -1           0.953558  \n",
       "7        -1           0.969306  \n",
       "8        -1           0.938658  \n",
       "9        -1           0.979164  \n",
       "...     ...                ...  \n",
       "2989     -1           0.975608  \n",
       "2992     -1           0.933957  \n",
       "2993     -1           0.938822  \n",
       "2997     -1           0.947751  \n",
       "2998     -1           0.931953  \n",
       "\n",
       "[1482 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_one_epoch_all_preds_df_negatives['cosine_similarity'].plot(kind='hist', bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of cosine_similarities for negative pairs after fine tuning 8 epochs')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "after_one_epoch_all_preds_df_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>text</th>\n",
       "      <th>time_series</th>\n",
       "      <th>label</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-14 23:13:20.863736</td>\n",
       "      <td>decline decrease drop negative loss</td>\n",
       "      <td>[[51], [50], [49], [48], [47]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-12 23:13:20.863736</td>\n",
       "      <td>negative decrease drop loss decline</td>\n",
       "      <td>[[78], [77], [76], [75], [74]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-11 23:13:20.863736</td>\n",
       "      <td>growth positive gain rise increase</td>\n",
       "      <td>[[67], [68], [69], [70], [71]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-09 23:13:20.863736</td>\n",
       "      <td>drop decrease decline negative loss</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>APPL</td>\n",
       "      <td>2024-08-08 23:13:20.863736</td>\n",
       "      <td>positive gain growth increase rise</td>\n",
       "      <td>[[75], [76], [77], [78], [79]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>2991</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-11 23:13:20.863736</td>\n",
       "      <td>gain growth rise increase positive</td>\n",
       "      <td>[[82], [83], [84], [85], [86]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>2994</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-08 23:13:20.863736</td>\n",
       "      <td>decline decrease negative loss drop</td>\n",
       "      <td>[[97], [96], [95], [94], [93]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2995</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-07 23:13:20.863736</td>\n",
       "      <td>rise positive increase growth gain</td>\n",
       "      <td>[[88], [89], [90], [91], [92]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2996</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-06 23:13:20.863736</td>\n",
       "      <td>positive gain growth increase rise</td>\n",
       "      <td>[[91], [92], [93], [94], [95]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2999</td>\n",
       "      <td>MSFN</td>\n",
       "      <td>2023-04-03 23:13:20.863736</td>\n",
       "      <td>negative decrease decline loss drop</td>\n",
       "      <td>[[57], [56], [55], [54], [53]]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id ticker                 Start Date  \\\n",
       "0        0   APPL 2024-08-14 23:13:20.863736   \n",
       "2        2   APPL 2024-08-12 23:13:20.863736   \n",
       "3        3   APPL 2024-08-11 23:13:20.863736   \n",
       "5        5   APPL 2024-08-09 23:13:20.863736   \n",
       "6        6   APPL 2024-08-08 23:13:20.863736   \n",
       "...    ...    ...                        ...   \n",
       "2991  2991   MSFN 2023-04-11 23:13:20.863736   \n",
       "2994  2994   MSFN 2023-04-08 23:13:20.863736   \n",
       "2995  2995   MSFN 2023-04-07 23:13:20.863736   \n",
       "2996  2996   MSFN 2023-04-06 23:13:20.863736   \n",
       "2999  2999   MSFN 2023-04-03 23:13:20.863736   \n",
       "\n",
       "                                     text                     time_series  \\\n",
       "0     decline decrease drop negative loss  [[51], [50], [49], [48], [47]]   \n",
       "2     negative decrease drop loss decline  [[78], [77], [76], [75], [74]]   \n",
       "3      growth positive gain rise increase  [[67], [68], [69], [70], [71]]   \n",
       "5     drop decrease decline negative loss  [[57], [56], [55], [54], [53]]   \n",
       "6      positive gain growth increase rise  [[75], [76], [77], [78], [79]]   \n",
       "...                                   ...                             ...   \n",
       "2991   gain growth rise increase positive  [[82], [83], [84], [85], [86]]   \n",
       "2994  decline decrease negative loss drop  [[97], [96], [95], [94], [93]]   \n",
       "2995   rise positive increase growth gain  [[88], [89], [90], [91], [92]]   \n",
       "2996   positive gain growth increase rise  [[91], [92], [93], [94], [95]]   \n",
       "2999  negative decrease decline loss drop  [[57], [56], [55], [54], [53]]   \n",
       "\n",
       "      label  cosine_similarity  \n",
       "0         1           0.969699  \n",
       "2         1           0.959337  \n",
       "3         1           0.967799  \n",
       "5         1           0.979208  \n",
       "6         1           0.955159  \n",
       "...     ...                ...  \n",
       "2991      1           0.945139  \n",
       "2994      1           0.934047  \n",
       "2995      1           0.937572  \n",
       "2996      1           0.934083  \n",
       "2999      1           0.979208  \n",
       "\n",
       "[1518 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_one_epoch_all_preds_df_positives['cosine_similarity'].plot(kind='hist', bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cosine Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of cosine_similarities for positive pairs after fine tuning 8 epochs')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "after_one_epoch_all_preds_df_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df['label'] == -1]['cosine_similarity'].plot(kind='hist', bins=30, alpha=0.5, color='red', label='Negative Pairs')\n",
    "\n",
    "# Histogram for category 1\n",
    "df[df['label'] == 1]['cosine_similarity'].plot(kind='hist', bins=30, alpha=0.5, color='blue', label='Positive Pairs')\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of cosine_similarities after fine tuning 8 epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stock_emotions_df \u001b[38;5;241m=\u001b[39m \u001b[43mdh\u001b[49m\u001b[38;5;241m.\u001b[39mget_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_emotions\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dh' is not defined"
     ]
    }
   ],
   "source": [
    "stock_emotions_df = dh.get_data(\"stock_emotions\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple it’s just too funny and easy to laugh at bears at this point. Why don’t you guys do something useful like find a good job so you can afford to buy Apple instead of just posting jealous hate and looking like a  [clown face] Apple once hits 300 today, needs another 100 points to reach 400 like that smart gentleman said on CNBC this am  [thumbs up medium skin tone]  Apple Bears & Shorts Later Today  [face with tears of joy] Apple who is ready to open tomorrow  at $290. It’s time  [pig face] Apple Green by morning my ass!! Y’all should have taken profits  [face with tears of joy]  [man facepalming light skin tone]  [eyes]  [red apple] Apple buy 300 call easy money  [rolling on the floor laughing] Apple maybe dan Ives at Wedbush can reimburse all you chasers for your losses. Or maybe not  [face with tears of joy] Apple short term  [bear]  people need to pull some off the table with all uncertainty floating around. This is just dicey Apple What makes bulls believe that Terrorist will stop  [stop sign]  launching rockets  [firecracker] Apple hahaha many bears buying put/sell. Strong strong but we wanna see 305 before close hahaha [rolling on the floor laughing]  [hundred points]  [backhand index pointing up]  [chart increasing with yen]  [dollar banknote] Apple again, shorts gonna buy put and sells, scared traders gonna take profit and selling shares/calls  [face with tears of joy]  if thats gonna happen, BUY THE DIPS! HOLD AND GO LONG! BUY NEW CAR OR WHAT EVER!  [backhand index pointing up]  [hundred points]  [dollar banknote]  [palms up together]  [chart increasing with yen]  End with 310-315 this week end next week Apple time to take a breather  [smiling face with sunglasses] Apple nice to look at my account today and see my shares up over 100% and climbing.  [clapping hands light skin tone] Apple Apple is going to keep on Running! Undervalued  [rocket] Apple thanks bears! ATH. 50% profit on calls overnight  [thumbs up light skin tone] Apple all those called getting burnt  [hot face] Apple i missed something.. Was whole day off, i couldn't buy anything. But i see bulls are fine! 330+ after earnings! Go short/longterms!  Have a great weekend [dollar banknote]  [hundred points]  [confetti ball] \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_emotions_df.iloc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[74.94999694824219],\n",
       " [74.59750366210938],\n",
       " [75.79750061035156],\n",
       " [77.40750122070312],\n",
       " [77.5824966430664]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_emotions_df.iloc[0][\"time_series\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "lags cannot go further than history length, found lag 12 while history length is only 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture_time_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([batch_size, prediction_length, num_time_features])\n\u001b[0;32m     39\u001b[0m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([batch_size, prediction_length])\n\u001b[1;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Step 4: Extract the embeddings\u001b[39;00m\n\u001b[0;32m     44\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# Shape: [batch_size, sequence_length, hidden_size]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1378\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[0;32m   1375\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1376\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1378\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1298\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;66;03m# lagged features\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m subsequences_length \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_length\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length\n\u001b[0;32m   1297\u001b[0m )\n\u001b[1;32m-> 1298\u001b[0m lagged_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lagged_subsequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsequences_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsequences_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m lags_shape \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1300\u001b[0m reshaped_lagged_sequence \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mreshape(lags_shape[\u001b[38;5;241m0\u001b[39m], lags_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1228\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.get_lagged_subsequences\u001b[1;34m(self, sequence, subsequences_length, shift)\u001b[0m\n\u001b[0;32m   1225\u001b[0m indices \u001b[38;5;241m=\u001b[39m [lag \u001b[38;5;241m-\u001b[39m shift \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlags_sequence]\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(indices) \u001b[38;5;241m+\u001b[39m subsequences_length \u001b[38;5;241m>\u001b[39m sequence_length:\n\u001b[1;32m-> 1228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlags cannot go further than history length, found lag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile history length is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[0;32m   1233\u001b[0m lagged_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag_index \u001b[38;5;129;01min\u001b[39;00m indices:\n",
      "\u001b[1;31mValueError\u001b[0m: lags cannot go further than history length, found lag 12 while history length is only 10"
     ]
    }
   ],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
    "\n",
    "# Step 1: Load the configuration and model\n",
    "config = TimeSeriesTransformerConfig(prediction_length=12, lags_sequence=[1, 2, 3])\n",
    "model = TimeSeriesTransformerModel(config)\n",
    "\n",
    "def ids_tensor(shape, vocab_size):\n",
    "    return torch.randint(low=0, high=vocab_size, size=shape)\n",
    "\n",
    "# Step 2: Pass your input time series data to the model\n",
    "# Assuming input_data is your tensor with shape [batch_size, sequence_length, num_features]\n",
    "# input_data should be a PyTorch tensor\n",
    "import torch\n",
    "\n",
    "# Example dimensions\n",
    "batch_size = 32\n",
    "sequence_length = 50\n",
    "num_features = 4\n",
    "\n",
    "inputs = dict()\n",
    "context_length = 5\n",
    "batch_size = 2\n",
    "cardinality = 5\n",
    "num_time_features = 10\n",
    "content_length = 8\n",
    "prediction_length = 2\n",
    "lags_sequence = [2, 3]\n",
    "past_length = context_length + max(lags_sequence)\n",
    "\n",
    "# encoder inputs\n",
    "#inputs[\"static_categorical_features\"] = ids_tensor([batch_size, 1], cardinality)\n",
    "inputs[\"static_real_features\"] = torch.randn([batch_size, 1])\n",
    "inputs[\"past_time_features\"] = torch.randn([batch_size, past_length, num_time_features])\n",
    "inputs[\"past_values\"] = torch.randn([batch_size, past_length])\n",
    "inputs[\"past_observed_mask\"] = torch.ones([batch_size, past_length])\n",
    "\n",
    "# decoder inputs\n",
    "inputs[\"future_time_features\"] = torch.randn([batch_size, prediction_length, num_time_features])\n",
    "inputs[\"future_values\"] = torch.randn([batch_size, prediction_length])\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Step 4: Extract the embeddings\n",
    "embeddings = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "# embeddings now contains the output from the last hidden layer, which you can use as desired.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerConfig {\n",
       "  \"_name_or_path\": \"huggingface/time-series-transformer-tourism-monthly\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"TimeSeriesTransformerForPrediction\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"cardinality\": [\n",
       "    366\n",
       "  ],\n",
       "  \"context_length\": 24,\n",
       "  \"d_model\": 26,\n",
       "  \"decoder_attention_heads\": 2,\n",
       "  \"decoder_ffn_dim\": 32,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 2,\n",
       "  \"distribution_output\": \"student_t\",\n",
       "  \"dropout\": 0.1,\n",
       "  \"embedding_dimension\": [\n",
       "    6\n",
       "  ],\n",
       "  \"encoder_attention_heads\": 2,\n",
       "  \"encoder_ffn_dim\": 32,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"feature_size\": 27,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 1,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"lags_sequence\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    23,\n",
       "    24,\n",
       "    25,\n",
       "    35,\n",
       "    36,\n",
       "    37\n",
       "  ],\n",
       "  \"loss\": \"nll\",\n",
       "  \"model_type\": \"time_series_transformer\",\n",
       "  \"num_dynamic_real_features\": 0,\n",
       "  \"num_parallel_samples\": 100,\n",
       "  \"num_static_categorical_features\": 1,\n",
       "  \"num_static_real_features\": 1,\n",
       "  \"num_time_features\": 2,\n",
       "  \"prediction_length\": 24,\n",
       "  \"scaling\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.44.0\",\n",
       "  \"use_cache\": true\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerModel\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"hf-internal-testing/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = TimeSeriesTransformerModel.from_pretrained(\"huggingface/time-series-transformer-tourism-monthly\")\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type tinytimemixer to instantiate a model of type time_series_transformer. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of TimeSeriesTransformerModel were not initialized from the model checkpoint at ibm-granite/granite-timeseries-ttm-v1 and are newly initialized: ['decoder.embed_positions.weight', 'decoder.layernorm_embedding.bias', 'decoder.layernorm_embedding.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.value_embedding.value_projection.weight', 'encoder.embed_positions.weight', 'encoder.layernorm_embedding.bias', 'encoder.layernorm_embedding.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.value_embedding.value_projection.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "lags cannot go further than history length, found lag 7 while history length is only 61",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 33\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m TimeSeriesTransformerModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mibm-granite/granite-timeseries-ttm-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#print(model.config)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#config.lags_sequence = [\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#    1,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m## during training, one provides both past and future values\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# as well as possible additional features\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_time_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_observed_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#static_categorical_features=batch[\"static_categorical_features\"],\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic_real_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#future_values=batch[\"future_values\"],\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#future_time_features=batch[\"future_time_features\"],\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1378\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[0;32m   1375\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1376\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1378\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1298\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;66;03m# lagged features\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m subsequences_length \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_length\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length\n\u001b[0;32m   1297\u001b[0m )\n\u001b[1;32m-> 1298\u001b[0m lagged_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lagged_subsequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsequences_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubsequences_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m lags_shape \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1300\u001b[0m reshaped_lagged_sequence \u001b[38;5;241m=\u001b[39m lagged_sequence\u001b[38;5;241m.\u001b[39mreshape(lags_shape[\u001b[38;5;241m0\u001b[39m], lags_shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1228\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.get_lagged_subsequences\u001b[1;34m(self, sequence, subsequences_length, shift)\u001b[0m\n\u001b[0;32m   1225\u001b[0m indices \u001b[38;5;241m=\u001b[39m [lag \u001b[38;5;241m-\u001b[39m shift \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlags_sequence]\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(indices) \u001b[38;5;241m+\u001b[39m subsequences_length \u001b[38;5;241m>\u001b[39m sequence_length:\n\u001b[1;32m-> 1228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlags cannot go further than history length, found lag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile history length is only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1231\u001b[0m     )\n\u001b[0;32m   1233\u001b[0m lagged_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag_index \u001b[38;5;129;01min\u001b[39;00m indices:\n",
      "\u001b[1;31mValueError\u001b[0m: lags cannot go further than history length, found lag 7 while history length is only 61"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerModel\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"hf-internal-testing/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = TimeSeriesTransformerModel.from_pretrained(\"ibm-granite/granite-timeseries-ttm-v1\")\n",
    "\n",
    "#print(model.config)\n",
    "#config.lags_sequence = [\n",
    "#    1,\n",
    "#    2,\n",
    "#    3,\n",
    "#    4,\n",
    "#    5,\n",
    "#    6,\n",
    "#    7,\n",
    "#    11,\n",
    "#    12,\n",
    "#    13,\n",
    "#    23,\n",
    "#    24,\n",
    "#    25,\n",
    "#    35,\n",
    "#    36,\n",
    "#    37\n",
    "#  ]\n",
    "## during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    #static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    #future_values=batch[\"future_values\"],\n",
    "    #future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "last_hidden_state = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static_categorical_features\n",
      "torch.Size([64, 1])\n",
      "static_real_features\n",
      "torch.Size([64, 1])\n",
      "past_time_features\n",
      "torch.Size([64, 61, 2])\n",
      "past_values\n",
      "torch.Size([64, 61])\n",
      "past_observed_mask\n",
      "torch.Size([64, 61])\n",
      "future_time_features\n",
      "torch.Size([64, 24, 2])\n",
      "future_values\n",
      "torch.Size([64, 24])\n",
      "future_observed_mask\n",
      "torch.Size([64, 24])\n"
     ]
    }
   ],
   "source": [
    "for key in batch.keys():\n",
    "\n",
    "    print(key)\n",
    "    print(batch[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1364,  2.2175],\n",
       "         [ 0.2273,  2.2201],\n",
       "         [ 0.3182,  2.2227],\n",
       "         ...,\n",
       "         [-0.0455,  2.3483],\n",
       "         [ 0.0455,  2.3502],\n",
       "         [ 0.1364,  2.3522]],\n",
       "\n",
       "        [[ 0.1364,  2.1847],\n",
       "         [ 0.2273,  2.1875],\n",
       "         [ 0.3182,  2.1903],\n",
       "         ...,\n",
       "         [-0.0455,  2.3243],\n",
       "         [ 0.0455,  2.3263],\n",
       "         [ 0.1364,  2.3284]],\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-0.2273,  0.6990],\n",
       "         [-0.1364,  0.7782],\n",
       "         [-0.0455,  0.8451]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.4091,  1.5563],\n",
       "         [ 0.5000,  1.5682],\n",
       "         [-0.5000,  1.5798]],\n",
       "\n",
       "        [[-0.4091,  1.7993],\n",
       "         [-0.3182,  1.8062],\n",
       "         [-0.2273,  1.8129],\n",
       "         ...,\n",
       "         [ 0.5000,  2.0828],\n",
       "         [-0.5000,  2.0864],\n",
       "         [-0.4091,  2.0899]],\n",
       "\n",
       "        [[ 0.5000,  1.1139],\n",
       "         [-0.5000,  1.1461],\n",
       "         [-0.4091,  1.1761],\n",
       "         ...,\n",
       "         [ 0.3182,  1.8513],\n",
       "         [ 0.4091,  1.8573],\n",
       "         [ 0.5000,  1.8633]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['past_time_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
    "\n",
    "# Initializing a default Time Series Transformer configuration\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=10)\n",
    "\n",
    "# Randomly initializing a model from the configuration\n",
    "model = TimeSeriesTransformerModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `prediction_length` config needs to be specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m configuration \u001b[38;5;241m=\u001b[39m AutoformerConfig(prediction_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Randomly initializing a model (with random weights) from the configuration\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Accessing the model configuration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m configuration \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\autoformer\\modeling_autoformer.py:1444\u001b[0m, in \u001b[0;36mAutoformerModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder \u001b[38;5;241m=\u001b[39m AutoformerFeatureEmbedder(\n\u001b[0;32m   1440\u001b[0m         cardinalities\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcardinality, embedding_dims\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_dimension\n\u001b[0;32m   1441\u001b[0m     )\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;66;03m# transformer encoder-decoder and mask initializer\u001b[39;00m\n\u001b[1;32m-> 1444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mAutoformerEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m AutoformerDecoder(config)\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;66;03m# used for decoder seasonal and trend initialization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\autoformer\\modeling_autoformer.py:1078\u001b[0m, in \u001b[0;36mAutoformerEncoder.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayerdrop \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mencoder_layerdrop\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mprediction_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `prediction_length` config needs to be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_embedding \u001b[38;5;241m=\u001b[39m AutoformerValueEmbedding(feature_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfeature_size, d_model\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39md_model)\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions \u001b[38;5;241m=\u001b[39m AutoformerSinusoidalPositionalEmbedding(\n\u001b[0;32m   1082\u001b[0m     config\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mprediction_length, config\u001b[38;5;241m.\u001b[39md_model\n\u001b[0;32m   1083\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The `prediction_length` config needs to be specified."
     ]
    }
   ],
   "source": [
    "from transformers import AutoformerConfig, AutoformerModel\n",
    "\n",
    "# Initializing a default Autoformer configuration\n",
    "configuration = AutoformerConfig(prediction_length=10)\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = AutoformerModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (744923598.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Load Model from HF Model Hub mentioning the branch name in revision field\n",
    "\n",
    "model = TinyTimeMixerForPrediction.from_pretrained(\n",
    "                \"https://huggingface.co/ibm/TTM\", revision=\"main\"\n",
    "            ) \n",
    "\n",
    "# Do zeroshot\n",
    "zeroshot_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=zeroshot_forecast_args,\n",
    "        )\n",
    "    \n",
    "\n",
    "zeroshot_output = zeroshot_trainer.evaluate(dset_test)\n",
    "\n",
    "\n",
    "# Freeze backbone and enable few-shot or finetuning:\n",
    "\n",
    "# freeze backbone\n",
    "for param in model.backbone.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "finetune_forecast_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=finetune_forecast_args,\n",
    "        train_dataset=dset_train,\n",
    "        eval_dataset=dset_val,\n",
    "        callbacks=[early_stopping_callback, tracking_callback],\n",
    "        optimizers=(optimizer, scheduler),\n",
    "    )\n",
    "finetune_forecast_trainer.train()\n",
    "fewshot_output = finetune_forecast_trainer.evaluate(dset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for monash_tsf contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/monash_tsf\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 25.6k/25.6k [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|██████████| 31.2k/31.2k [00:00<00:00, 1.96MB/s]\n",
      "Downloading extra modules: 100%|██████████| 7.54k/7.54k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 200k/200k [00:01<00:00, 194kB/s]  \n",
      "Generating train split: 100%|██████████| 366/366 [00:00<00:00, 1062.90 examples/s]\n",
      "Generating test split: 100%|██████████| 366/366 [00:00<00:00, 1172.30 examples/s]\n",
      "Generating validation split: 100%|██████████| 366/366 [00:00<00:00, 1270.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"monash_tsf\", \"tourism_monthly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'])\n",
      "1979-01-01 00:00:00\n",
      "[1149.8699951171875, 1053.8001708984375, 1388.8797607421875, 1783.3702392578125, 1921.025146484375, 2704.94482421875, 4184.41357421875, 4148.35400390625, 2620.72509765625, 1650.300048828125, 1115.9200439453125, 1370.6251220703125, 1096.31494140625, 978.4600219726562, 1294.68505859375, 1480.465087890625, 1748.865234375, 2216.920166015625, 4690.5185546875, 4682.8642578125, 2459.579833984375, 1484.4901123046875, 1028.985107421875, 1109.3648681640625, 960.8751220703125, 896.35009765625, 1118.6551513671875, 1619.9949951171875, 1847.994873046875, 2367.044921875, 4991.16015625, 4772.9443359375, 2894.678466796875, 1860.4801025390625, 1185.150146484375, 1313.659912109375, 1160.9150390625, 1061.5048828125, 1301.77001953125, 1794.3797607421875, 2106.455078125, 2789.034912109375, 4917.8466796875, 4994.4833984375, 3016.754150390625, 1941.505126953125, 1234.135009765625, 1378.72021484375, 1182.9749755859375, 1081.6600341796875, 1424.110107421875, 1774.5350341796875, 2115.420166015625, 2804.840087890625, 4849.498046875, 4937.47509765625, 3074.2236328125, 2063.42529296875, 1297.355224609375, 1350.710205078125, 1224.360107421875, 1165.815185546875, 1409.3299560546875, 2116.5498046875, 2357.135009765625, 2995.0703125, 5295.2119140625, 4957.90478515625, 3321.959228515625, 2221.18017578125, 1345.9000244140625, 1514.01513671875, 1239.5501708984375, 1172.159912109375, 1518.9752197265625, 1996.8751220703125, 2248.68505859375, 3053.440185546875, 5019.45361328125, 5466.7802734375, 3235.167724609375, 2157.97998046875, 1379.7252197265625, 1728.0400390625, 1350.10986328125, 1216.014892578125, 1751.3251953125, 1805.320068359375, 2570.02490234375, 3204.240234375, 5395.72021484375, 6078.82861328125, 3587.098388671875, 2285.195068359375, 1582.18994140625, 1787.4298095703125, 1554.8701171875, 1409.8648681640625, 1612.125, 2286.239990234375, 2913.755126953125, 3645.908447265625, 5956.70849609375, 6326.97509765625, 3914.66015625, 2617.675048828125, 1675.1650390625, 2139.219970703125, 1715.4898681640625, 1663.5799560546875, 2053.699951171875, 2354.929931640625, 3038.591796875, 3470.609375, 6606.18359375, 6587.63671875, 4133.78271484375, 2960.0244140625, 1762.5849609375, 2125.64013671875, 1815.9150390625, 1632.31494140625, 2210.39501953125, 2210.215087890625, 3099.269287109375, 3468.77783203125, 6482.92529296875, 6665.48486328125, 4006.36181640625, 2882.3349609375, 1775.2498779296875, 2171.64990234375, 1796.4749755859375, 1692.349853515625, 1949.78515625, 2680.630126953125, 2645.949951171875, 3414.742919921875, 5772.876953125]\n",
      "[0]\n",
      "None\n",
      "T1\n"
     ]
    }
   ],
   "source": [
    "dataset\n",
    "train_example = dataset['train'][0]\n",
    "print(train_example.keys())\n",
    "print(train_example['start'])\n",
    "print(train_example['target'])\n",
    "print(train_example['feat_static_cat'])\n",
    "print(train_example['feat_dynamic_real'])\n",
    "print(train_example['item_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type tinytimemixer to instantiate a model of type time_series_transformer. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of TimeSeriesTransformerModel were not initialized from the model checkpoint at ibm-granite/granite-timeseries-ttm-v1 and are newly initialized: ['decoder.embed_positions.weight', 'decoder.layernorm_embedding.bias', 'decoder.layernorm_embedding.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.value_embedding.value_projection.weight', 'encoder.embed_positions.weight', 'encoder.layernorm_embedding.bias', 'encoder.layernorm_embedding.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.value_embedding.value_projection.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (50) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m past_observed_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, sequence_length))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Now you can pass these to the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_series_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the last hidden state\u001b[39;00m\n\u001b[0;32m     30\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1378\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[0;32m   1375\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1376\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1378\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1269\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1267\u001b[0m context \u001b[38;5;241m=\u001b[39m past_values[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length :]\n\u001b[0;32m   1268\u001b[0m observed_context \u001b[38;5;241m=\u001b[39m past_observed_mask[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length :]\n\u001b[1;32m-> 1269\u001b[0m _, loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1271\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1272\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mcat((past_values, future_values), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (past_values \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m   1275\u001b[0m )\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;66;03m# static features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:111\u001b[0m, in \u001b[0;36mTimeSeriesStdScaler.forward\u001b[1;34m(self, data, observed_indicator)\u001b[0m\n\u001b[0;32m    109\u001b[0m denominator \u001b[38;5;241m=\u001b[39m observed_indicator\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeepdim)\n\u001b[0;32m    110\u001b[0m denominator \u001b[38;5;241m=\u001b[39m denominator\u001b[38;5;241m.\u001b[39mclamp_min(\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m loc \u001b[38;5;241m=\u001b[39m (\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobserved_indicator\u001b[49m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeepdim) \u001b[38;5;241m/\u001b[39m denominator\n\u001b[0;32m    113\u001b[0m variance \u001b[38;5;241m=\u001b[39m (((data \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m*\u001b[39m observed_indicator) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeepdim) \u001b[38;5;241m/\u001b[39m denominator\n\u001b[0;32m    114\u001b[0m scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminimum_scale)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (50) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the IBM Granite model\n",
    "model = TimeSeriesTransformerModel.from_pretrained(\"ibm-granite/granite-timeseries-ttm-v1\")\n",
    "\n",
    "import torch\n",
    "\n",
    "# Assuming you have the time series data\n",
    "batch_size = 10\n",
    "sequence_length = 50\n",
    "feature_dim = 20\n",
    "\n",
    "# Example time series data with shape (batch_size, sequence_length, feature_dim)\n",
    "time_series_data = torch.rand((batch_size, sequence_length, feature_dim)).float()\n",
    "\n",
    "# Generating past_time_features, could be similar to time_series_data or additional features\n",
    "num_additional_features = 5  # Number of additional time-related features\n",
    "past_time_features = torch.rand((batch_size, sequence_length, num_additional_features)).float()\n",
    "\n",
    "# Generating past_observed_mask, a binary mask indicating observed time steps\n",
    "# Assuming all time steps are observed in this example\n",
    "past_observed_mask = torch.ones((batch_size, sequence_length)).float()\n",
    "\n",
    "# Now you can pass these to the model\n",
    "outputs = model(time_series_data, past_time_features, past_observed_mask)\n",
    "\n",
    "# Get the last hidden state\n",
    "last_hidden_state = outputs.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>72.482498</td>\n",
       "      <td>73.419998</td>\n",
       "      <td>72.379997</td>\n",
       "      <td>73.412498</td>\n",
       "      <td>71.520821</td>\n",
       "      <td>100805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>73.797501</td>\n",
       "      <td>75.087502</td>\n",
       "      <td>73.152649</td>\n",
       "      <td>135480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>74.287498</td>\n",
       "      <td>75.144997</td>\n",
       "      <td>74.125000</td>\n",
       "      <td>74.357498</td>\n",
       "      <td>72.441460</td>\n",
       "      <td>146322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.447502</td>\n",
       "      <td>74.989998</td>\n",
       "      <td>73.187500</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>73.018677</td>\n",
       "      <td>118387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>74.959999</td>\n",
       "      <td>75.224998</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>72.675278</td>\n",
       "      <td>108872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>131.320007</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>131.100006</td>\n",
       "      <td>131.970001</td>\n",
       "      <td>129.679718</td>\n",
       "      <td>54930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>137.339996</td>\n",
       "      <td>133.509995</td>\n",
       "      <td>136.690002</td>\n",
       "      <td>134.317825</td>\n",
       "      <td>124486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>132.529404</td>\n",
       "      <td>121047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>135.580002</td>\n",
       "      <td>135.990005</td>\n",
       "      <td>133.399994</td>\n",
       "      <td>133.720001</td>\n",
       "      <td>131.399368</td>\n",
       "      <td>96452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>134.740005</td>\n",
       "      <td>131.720001</td>\n",
       "      <td>132.690002</td>\n",
       "      <td>130.387222</td>\n",
       "      <td>99116600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0    2019-12-31   72.482498   73.419998   72.379997   73.412498   71.520821   \n",
       "1    2020-01-02   74.059998   75.150002   73.797501   75.087502   73.152649   \n",
       "2    2020-01-03   74.287498   75.144997   74.125000   74.357498   72.441460   \n",
       "3    2020-01-06   73.447502   74.989998   73.187500   74.949997   73.018677   \n",
       "4    2020-01-07   74.959999   75.224998   74.370003   74.597504   72.675278   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "249  2020-12-24  131.320007  133.460007  131.100006  131.970001  129.679718   \n",
       "250  2020-12-28  133.990005  137.339996  133.509995  136.690002  134.317825   \n",
       "251  2020-12-29  138.050003  138.789993  134.339996  134.869995  132.529404   \n",
       "252  2020-12-30  135.580002  135.990005  133.399994  133.720001  131.399368   \n",
       "253  2020-12-31  134.080002  134.740005  131.720001  132.690002  130.387222   \n",
       "\n",
       "        Volume  \n",
       "0    100805600  \n",
       "1    135480400  \n",
       "2    146322800  \n",
       "3    118387200  \n",
       "4    108872000  \n",
       "..         ...  \n",
       "249   54930100  \n",
       "250  124486200  \n",
       "251  121047300  \n",
       "252   96452100  \n",
       "253   99116600  \n",
       "\n",
       "[254 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_values: tensor([75.7975, 77.4075, 77.5825, 79.2400, 78.1700])\n",
      "past_time_features: tensor([2., 3., 4., 0., 1.])\n",
      "past_observed_mask: tensor([1., 1., 1., 1., 1.])\n",
      "static_real_features: tensor([])\n",
      "future_values: tensor([77.8350, 78.8100, 79.6825])\n",
      "future_time_features: tensor([2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './data/stock_emotions/price/AAPL.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select a single row to predict from (assuming row 10)\n",
    "row_idx = 10\n",
    "\n",
    "# Define past and future horizons\n",
    "past_horizon = 5\n",
    "future_horizon = 3\n",
    "\n",
    "# Extract past values\n",
    "past_values = df['Close'].iloc[row_idx-past_horizon:row_idx].values\n",
    "past_values = torch.tensor(past_values, dtype=torch.float32)\n",
    "\n",
    "# Extract past time features (e.g., day of the week)\n",
    "past_time_features = pd.to_datetime(df['Date'].iloc[row_idx-past_horizon:row_idx])\n",
    "past_time_features = torch.tensor(past_time_features.dt.dayofweek.values, dtype=torch.float32)\n",
    "\n",
    "# Generate a binary observed mask (assume all values are observed in this example)\n",
    "past_observed_mask = torch.ones(past_horizon, dtype=torch.float32)\n",
    "\n",
    "# Assuming no static features for this example\n",
    "static_real_features = torch.tensor([], dtype=torch.float32)\n",
    "\n",
    "# Extract future values (target values)\n",
    "future_values = df['Close'].iloc[row_idx:row_idx+future_horizon].values\n",
    "future_values = torch.tensor(future_values, dtype=torch.float32)\n",
    "\n",
    "# Extract future time features\n",
    "future_time_features = pd.to_datetime(df['Date'].iloc[row_idx:row_idx+future_horizon])\n",
    "future_time_features = torch.tensor(future_time_features.dt.dayofweek.values, dtype=torch.float32)\n",
    "\n",
    "# Print out the variables\n",
    "print(\"past_values:\", past_values)\n",
    "print(\"past_time_features:\", past_time_features)\n",
    "print(\"past_observed_mask:\", past_observed_mask)\n",
    "print(\"static_real_features:\", static_real_features)\n",
    "print(\"future_values:\", future_values)\n",
    "print(\"future_time_features:\", future_time_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type tinytimemixer to instantiate a model of type time_series_transformer. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of TimeSeriesTransformerModel were not initialized from the model checkpoint at ibm-granite/granite-timeseries-ttm-v1 and are newly initialized: ['decoder.embed_positions.weight', 'decoder.layernorm_embedding.bias', 'decoder.layernorm_embedding.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.value_embedding.value_projection.weight', 'encoder.embed_positions.weight', 'encoder.layernorm_embedding.bias', 'encoder.layernorm_embedding.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.value_embedding.value_projection.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TimeSeriesTransformerModel\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = TimeSeriesTransformerModel.from_pretrained('ibm-granite/granite-timeseries-ttm-v1')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Example data from earlier steps\n",
    "past_values = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0]).unsqueeze(0)  # Shape: [batch_size, past_horizon]\n",
    "past_time_features = torch.tensor([0, 1, 2, 3, 4]).unsqueeze(0)     # Shape: [batch_size, past_horizon, num_features]\n",
    "past_observed_mask = torch.tensor([1, 1, 1, 1, 1]).unsqueeze(0)     # Shape: [batch_size, past_horizon]\n",
    "static_real_features =  torch.empty((batch_size, 1, 0)).float().unsqueeze(0)                # Shape: [batch_size, num_static_features]\n",
    "future_values = torch.tensor([6.0, 7.0, 8.0]).unsqueeze(0)          # Shape: [batch_size, future_horizon]\n",
    "future_time_features = torch.tensor([5, 6, 0]).unsqueeze(0)         # Shape: [batch_size, future_horizon, num_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 4 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Pass the inputs through the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract the last hidden state from the model's output\u001b[39;00m\n\u001b[0;32m     12\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1378\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[0;32m   1375\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1376\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1378\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1283\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1280\u001b[0m static_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((log_abs_loc, log_scale), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m static_real_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1283\u001b[0m     static_feat \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_feat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m static_categorical_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1285\u001b[0m     embedded_cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(static_categorical_features)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 2"
     ]
    }
   ],
   "source": [
    "# Pass the inputs through the model\n",
    "outputs = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    static_real_features=static_real_features,\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features,\n",
    ")\n",
    "\n",
    "# Extract the last hidden state from the model's output\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# Print the last hidden state\n",
    "print(\"Last Hidden State:\", last_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'static_categorical_features': tensor([[29],\n",
       "         [31],\n",
       "         [32],\n",
       "         [32],\n",
       "         [32],\n",
       "         [33],\n",
       "         [33],\n",
       "         [34],\n",
       "         [34],\n",
       "         [35],\n",
       "         [37],\n",
       "         [39],\n",
       "         [44],\n",
       "         [46],\n",
       "         [47],\n",
       "         [47],\n",
       "         [49],\n",
       "         [50],\n",
       "         [50],\n",
       "         [51],\n",
       "         [52],\n",
       "         [53],\n",
       "         [53],\n",
       "         [54],\n",
       "         [54],\n",
       "         [56],\n",
       "         [56],\n",
       "         [59],\n",
       "         [60],\n",
       "         [62],\n",
       "         [63],\n",
       "         [66],\n",
       "         [67],\n",
       "         [67],\n",
       "         [68],\n",
       "         [70],\n",
       "         [70],\n",
       "         [71],\n",
       "         [72],\n",
       "         [73],\n",
       "         [75],\n",
       "         [76],\n",
       "         [76],\n",
       "         [77],\n",
       "         [77],\n",
       "         [78],\n",
       "         [78],\n",
       "         [79],\n",
       "         [80],\n",
       "         [81],\n",
       "         [82],\n",
       "         [83],\n",
       "         [83],\n",
       "         [84],\n",
       "         [84],\n",
       "         [85],\n",
       "         [86],\n",
       "         [86],\n",
       "         [86],\n",
       "         [87],\n",
       "         [88],\n",
       "         [90],\n",
       "         [92],\n",
       "         [93]]),\n",
       " 'static_real_features': tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       " 'past_time_features': tensor([[[ 0.1364,  2.2175],\n",
       "          [ 0.2273,  2.2201],\n",
       "          [ 0.3182,  2.2227],\n",
       "          ...,\n",
       "          [-0.0455,  2.3483],\n",
       "          [ 0.0455,  2.3502],\n",
       "          [ 0.1364,  2.3522]],\n",
       " \n",
       "         [[ 0.1364,  2.1847],\n",
       "          [ 0.2273,  2.1875],\n",
       "          [ 0.3182,  2.1903],\n",
       "          ...,\n",
       "          [-0.0455,  2.3243],\n",
       "          [ 0.0455,  2.3263],\n",
       "          [ 0.1364,  2.3284]],\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [-0.2273,  0.6990],\n",
       "          [-0.1364,  0.7782],\n",
       "          [-0.0455,  0.8451]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.4091,  1.5563],\n",
       "          [ 0.5000,  1.5682],\n",
       "          [-0.5000,  1.5798]],\n",
       " \n",
       "         [[-0.4091,  1.7993],\n",
       "          [-0.3182,  1.8062],\n",
       "          [-0.2273,  1.8129],\n",
       "          ...,\n",
       "          [ 0.5000,  2.0828],\n",
       "          [-0.5000,  2.0864],\n",
       "          [-0.4091,  2.0899]],\n",
       " \n",
       "         [[ 0.5000,  1.1139],\n",
       "          [-0.5000,  1.1461],\n",
       "          [-0.4091,  1.1761],\n",
       "          ...,\n",
       "          [ 0.3182,  1.8513],\n",
       "          [ 0.4091,  1.8573],\n",
       "          [ 0.5000,  1.8633]]]),\n",
       " 'past_values': tensor([[19081., 20436., 27477.,  ..., 29401., 34654., 25116.],\n",
       "         [14819., 18318., 23751.,  ..., 19311., 22673., 22400.],\n",
       "         [    0.,     0.,     0.,  ...,  2254.,  1505.,  1369.],\n",
       "         ...,\n",
       "         [    0.,     0.,     0.,  ...,  1963.,  2168.,  2995.],\n",
       "         [  717.,   295.,   193.,  ...,   425.,  1483.,  1703.],\n",
       "         [  130.,   142.,   283.,  ...,   234.,   259.,   465.]]),\n",
       " 'past_observed_mask': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " 'future_time_features': tensor([[[ 0.2273,  2.3541],\n",
       "          [ 0.3182,  2.3560],\n",
       "          [ 0.4091,  2.3579],\n",
       "          ...,\n",
       "          [-0.0455,  2.3927],\n",
       "          [ 0.0455,  2.3945],\n",
       "          [ 0.1364,  2.3962]],\n",
       " \n",
       "         [[ 0.2273,  2.3304],\n",
       "          [ 0.3182,  2.3324],\n",
       "          [ 0.4091,  2.3345],\n",
       "          ...,\n",
       "          [-0.0455,  2.3711],\n",
       "          [ 0.0455,  2.3729],\n",
       "          [ 0.1364,  2.3747]],\n",
       " \n",
       "         [[ 0.0455,  0.9031],\n",
       "          [ 0.1364,  0.9542],\n",
       "          [ 0.2273,  1.0000],\n",
       "          ...,\n",
       "          [-0.2273,  1.4624],\n",
       "          [-0.1364,  1.4771],\n",
       "          [-0.0455,  1.4914]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.4091,  1.5911],\n",
       "          [-0.3182,  1.6021],\n",
       "          [-0.2273,  1.6128],\n",
       "          ...,\n",
       "          [ 0.4091,  1.7782],\n",
       "          [ 0.5000,  1.7853],\n",
       "          [-0.5000,  1.7924]],\n",
       " \n",
       "         [[-0.3182,  2.0934],\n",
       "          [-0.2273,  2.0969],\n",
       "          [-0.1364,  2.1004],\n",
       "          ...,\n",
       "          [ 0.5000,  2.1614],\n",
       "          [-0.5000,  2.1644],\n",
       "          [-0.4091,  2.1673]],\n",
       " \n",
       "         [[-0.5000,  1.8692],\n",
       "          [-0.4091,  1.8751],\n",
       "          [-0.3182,  1.8808],\n",
       "          ...,\n",
       "          [ 0.3182,  1.9777],\n",
       "          [ 0.4091,  1.9823],\n",
       "          [ 0.5000,  1.9868]]]),\n",
       " 'future_values': tensor([[22816., 35055., 33590.,  ..., 42358., 43828., 33141.],\n",
       "         [28998., 38666., 47152.,  ..., 23249., 35239., 33423.],\n",
       "         [ 2680.,  1820.,  1743.,  ...,  2551.,  1586.,  1889.],\n",
       "         ...,\n",
       "         [ 2223.,  2569.,  2148.,  ...,  2496.,  2608.,  3303.],\n",
       "         [  498.,   481.,   259.,  ...,   343.,  1291.,  2323.],\n",
       "         [  352.,   543.,   262.,  ...,   310.,   312.,   477.]]),\n",
       " 'future_observed_mask': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type tinytimemixer to instantiate a model of type time_series_transformer. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of TimeSeriesTransformerModel were not initialized from the model checkpoint at ibm-granite/granite-timeseries-ttm-v1 and are newly initialized: ['decoder.embed_positions.weight', 'decoder.layernorm_embedding.bias', 'decoder.layernorm_embedding.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.value_embedding.value_projection.weight', 'encoder.embed_positions.weight', 'encoder.layernorm_embedding.bias', 'encoder.layernorm_embedding.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.value_embedding.value_projection.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m future_time_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m0\u001b[39m]])  \u001b[38;5;66;03m# Shape: [batch_size, future_horizon, num_features]\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Pass the inputs through the model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass an empty tensor here\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Extract the last hidden state from the model's output\u001b[39;00m\n\u001b[0;32m     31\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1378\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.forward\u001b[1;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[0;32m   1375\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   1376\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1378\u001b[0m transformer_inputs, loc, scale, static_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_categorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_real_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_real_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_time_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1389\u001b[0m     enc_input \u001b[38;5;241m=\u001b[39m transformer_inputs[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\models\\time_series_transformer\\modeling_time_series_transformer.py:1290\u001b[0m, in \u001b[0;36mTimeSeriesTransformerModel.create_network_inputs\u001b[1;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[0;32m   1287\u001b[0m expanded_static_feat \u001b[38;5;241m=\u001b[39m static_feat\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, time_feat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;66;03m# all features\u001b[39;00m\n\u001b[1;32m-> 1290\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_static_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_feat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;66;03m# lagged features\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m subsequences_length \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_length\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m future_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcontext_length\n\u001b[0;32m   1297\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TimeSeriesTransformerModel\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = TimeSeriesTransformerModel.from_pretrained('ibm-granite/granite-timeseries-ttm-v1')\n",
    "model.eval()\n",
    "\n",
    "# Example data from earlier steps (modify as needed for your data)\n",
    "batch_size = 1\n",
    "past_values = torch.tensor([[1.0, 2.0, 3.0, 4.0, 5.0]])  # Shape: [batch_size, past_horizon]\n",
    "past_time_features = torch.tensor([[0, 1, 2, 3, 4]])     # Shape: [batch_size, past_horizon, num_features]\n",
    "past_observed_mask = torch.tensor([[1, 1, 1, 1, 1]])     # Shape: [batch_size, past_horizon]\n",
    "\n",
    "# If no static features, create an empty tensor with the correct shape\n",
    "static_real_features = torch.empty((batch_size, 0)).float()  # Shape: [batch_size, 1, 0]\n",
    "\n",
    "future_values = torch.tensor([[6.0, 7.0, 8.0]])  # Shape: [batch_size, future_horizon]\n",
    "future_time_features = torch.tensor([[5, 6, 0]])  # Shape: [batch_size, future_horizon, num_features]\n",
    "\n",
    "# Pass the inputs through the model\n",
    "outputs = model(\n",
    "    past_values=past_values,\n",
    "    past_time_features=past_time_features,\n",
    "    past_observed_mask=past_observed_mask,\n",
    "    static_real_features=static_real_features,  # Pass an empty tensor here\n",
    "    future_values=future_values,\n",
    "    future_time_features=future_time_features,\n",
    ")\n",
    "\n",
    "# Extract the last hidden state from the model's output\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# Print the last hidden state\n",
    "print(\"Last Hidden State:\", last_hidden_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\eoinp\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\monash_tsf\\fc869f3ae1577c9def2a919ab1dd0c3d4a7a44826b8e0e8fa423bb0161b629e2 (last modified on Sat Aug 17 09:14:11 2024) since it couldn't be found locally at monash_tsf, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"monash_tsf\", \"tourism_monthly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example = dataset['train'][0]\n",
    "train_example[\"start\"]\n",
    "validation_example = dataset['validation'][0]\n",
    "validation_example.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1M\"\n",
    "prediction_length = 24\n",
    "\n",
    "assert len(train_example[\"target\"]) + prediction_length == len(\n",
    "    validation_example[\"target\"]\n",
    ")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "@lru_cache(10_000)\n",
    "def convert_to_pandas_period(date, freq):\n",
    "    return pd.Period(date, freq)\n",
    "\n",
    "def transform_start_field(batch, freq):\n",
    "    batch[\"start\"] = [convert_to_pandas_period(date, freq) for date in batch[\"start\"]]\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
    "test_dataset.set_transform(partial(transform_start_field, freq=freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7611.0,\n",
       " 6859.0,\n",
       " 9247.0,\n",
       " 10924.0,\n",
       " 9064.0,\n",
       " 7417.0,\n",
       " 10467.0,\n",
       " 7921.0,\n",
       " 8235.0,\n",
       " 12978.0,\n",
       " 11397.0,\n",
       " 11425.0,\n",
       " 9340.0,\n",
       " 8487.0,\n",
       " 11359.0,\n",
       " 10291.0,\n",
       " 9239.0,\n",
       " 8106.0,\n",
       " 10171.0,\n",
       " 8871.0,\n",
       " 8987.0,\n",
       " 15119.0,\n",
       " 14205.0,\n",
       " 13561.0,\n",
       " 12391.0,\n",
       " 11800.0,\n",
       " 13638.0,\n",
       " 11471.0,\n",
       " 12288.0,\n",
       " 10817.0,\n",
       " 13015.0,\n",
       " 10553.0,\n",
       " 10932.0,\n",
       " 17869.0,\n",
       " 16805.0,\n",
       " 14822.0,\n",
       " 14140.0,\n",
       " 12626.0,\n",
       " 16191.0,\n",
       " 14237.0,\n",
       " 12823.0,\n",
       " 10632.0,\n",
       " 12924.0,\n",
       " 10015.0,\n",
       " 10849.0,\n",
       " 18510.0,\n",
       " 17769.0,\n",
       " 15308.0,\n",
       " 14783.0,\n",
       " 11863.0,\n",
       " 17376.0,\n",
       " 13007.0,\n",
       " 12380.0,\n",
       " 9094.0,\n",
       " 10214.0,\n",
       " 7818.0,\n",
       " 8683.0,\n",
       " 14401.0,\n",
       " 15375.0,\n",
       " 15515.0,\n",
       " 12764.0,\n",
       " 12913.0,\n",
       " 15718.0,\n",
       " 12470.0,\n",
       " 12089.0,\n",
       " 10177.0,\n",
       " 11939.0,\n",
       " 9677.0,\n",
       " 9288.0,\n",
       " 15847.0,\n",
       " 15766.0,\n",
       " 17047.0,\n",
       " 13725.0,\n",
       " 10226.0,\n",
       " 13492.0,\n",
       " 12196.0,\n",
       " 12027.0,\n",
       " 11208.0,\n",
       " 13302.0,\n",
       " 10554.0,\n",
       " 10411.0,\n",
       " 17860.0,\n",
       " 17660.0,\n",
       " 19123.0,\n",
       " 16667.0,\n",
       " 13534.0,\n",
       " 16584.0,\n",
       " 14493.0,\n",
       " 13732.0,\n",
       " 11641.0,\n",
       " 14468.0,\n",
       " 11760.0,\n",
       " 11576.0,\n",
       " 18495.0,\n",
       " 18417.0,\n",
       " 18864.0,\n",
       " 15338.0,\n",
       " 15066.0,\n",
       " 16743.0,\n",
       " 15040.0,\n",
       " 14920.0,\n",
       " 12256.0,\n",
       " 16268.0,\n",
       " 13082.0,\n",
       " 12236.0,\n",
       " 20325.0,\n",
       " 19836.0,\n",
       " 18322.0,\n",
       " 17151.0,\n",
       " 13018.0,\n",
       " 18585.0,\n",
       " 16094.0,\n",
       " 15018.0,\n",
       " 12455.0,\n",
       " 15644.0,\n",
       " 12648.0,\n",
       " 11248.0,\n",
       " 17809.0,\n",
       " 18251.0,\n",
       " 17369.0,\n",
       " 14968.0,\n",
       " 12571.0,\n",
       " 16676.0,\n",
       " 14378.0,\n",
       " 13986.0,\n",
       " 12351.0,\n",
       " 15576.0,\n",
       " 12986.0,\n",
       " 10762.0,\n",
       " 16629.0,\n",
       " 16383.0,\n",
       " 17390.0,\n",
       " 19643.0,\n",
       " 14097.0,\n",
       " 21439.0,\n",
       " 16345.0,\n",
       " 15189.0,\n",
       " 12956.0,\n",
       " 16947.0,\n",
       " 13236.0,\n",
       " 10964.0,\n",
       " 16477.0,\n",
       " 15731.0,\n",
       " 12904.0,\n",
       " 14661.0,\n",
       " 13794.0,\n",
       " 20844.0,\n",
       " 17134.0,\n",
       " 16427.0,\n",
       " 14506.0,\n",
       " 13356.0,\n",
       " 13690.0,\n",
       " 12171.0,\n",
       " 18605.0,\n",
       " 18411.0,\n",
       " 18747.0,\n",
       " 16132.0,\n",
       " 14573.0,\n",
       " 19116.0,\n",
       " 17322.0,\n",
       " 16402.0,\n",
       " 13640.0,\n",
       " 16710.0,\n",
       " 15751.0,\n",
       " 12804.0,\n",
       " 20712.0,\n",
       " 23253.0,\n",
       " 21986.0,\n",
       " 17988.0,\n",
       " 14599.0,\n",
       " 22193.0,\n",
       " 19324.0,\n",
       " 17435.0,\n",
       " 14650.0,\n",
       " 18571.0,\n",
       " 17641.0,\n",
       " 13983.0,\n",
       " 24130.0,\n",
       " 25334.0,\n",
       " 20337.0,\n",
       " 18946.0,\n",
       " 17229.0,\n",
       " 23880.0,\n",
       " 21507.0,\n",
       " 20808.0,\n",
       " 16336.0,\n",
       " 20887.0,\n",
       " 20106.0,\n",
       " 16468.0,\n",
       " 25025.0,\n",
       " 27221.0,\n",
       " 24682.0,\n",
       " 20114.0,\n",
       " 21251.0,\n",
       " 26398.0,\n",
       " 21951.0,\n",
       " 20521.0,\n",
       " 16630.0,\n",
       " 20347.0,\n",
       " 18710.0,\n",
       " 14964.0,\n",
       " 21900.0,\n",
       " 23807.0,\n",
       " 23114.0,\n",
       " 21864.0,\n",
       " 17663.0,\n",
       " 25826.0,\n",
       " 24541.0,\n",
       " 21020.0,\n",
       " 17764.0,\n",
       " 20651.0,\n",
       " 19040.0,\n",
       " 17065.0,\n",
       " 26673.0,\n",
       " 28147.0,\n",
       " 24713.0]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "\n",
    "lags_sequence = get_lags_for_frequency(freq)\n",
    "print(lags_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000012F1E622F10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/gluonts/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000012F1E632390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/gluonts/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000012F1E633110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/gluonts/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000012F1E633A10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/gluonts/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000012F1E6384D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/gluonts/\n",
      "ERROR: Could not find a version that satisfies the requirement gluonts (from versions: none)\n",
      "ERROR: No matching distribution found for gluonts\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gluonts ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "\n",
    "time_features = time_features_from_frequency_str(freq)\n",
    "print(time_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text_tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m TimeSeriesTransformerModel(config)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_helper_v2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdh\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstock_emotions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m past_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_series\u001b[39m\u001b[38;5;124m\"\u001b[39m]]])  \u001b[38;5;66;03m#torch.rand(32, k)  \u001b[39;00m\n\u001b[0;32m     37\u001b[0m past_observed_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, k)\n",
      "File \u001b[1;32mc:\\Users\\eoinp\\Desktop\\University\\Honours\\implementation\\honours-fin-sentiment\\data_helper_v2.py:381\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(data_source, model, text_window, ts_window, days_away, negative_label, text_concatenation, negative_creation, batch_size, num_workers, device)\u001b[0m\n\u001b[0;32m    378\u001b[0m df \u001b[38;5;241m=\u001b[39m _helper_create_past_time_features_from_date(df\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m#handle split, Dataset and DataLoader\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m _helper_get_tvt_splits(df, text_tokenizer\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_tokenizer\u001b[49m(), transformer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    383\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[0;32m    384\u001b[0m val_dataloader   \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text_tokenizer'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import TimeSeriesTransformerModel, TimeSeriesTransformerConfig\n",
    "k = 5 #number of inputs\n",
    "lags_sequence=[1, 2, 3]\n",
    "context_length=2\n",
    "#context_lag = \n",
    "num_features = 2\n",
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=0,  \n",
    "    context_length=context_length,\n",
    "    #decoder_attention_heads=1,\n",
    "    #encoder_attention_heads=1,\n",
    "    #d_model=74,\n",
    "    lags_sequence=lags_sequence,\n",
    "    feature_size=len(lags_sequence) + num_features + 2\n",
    ")\n",
    "\n",
    "#Notes:\n",
    "\"\"\"\n",
    "- Length of k in the below torch tensors need to be size: context_length + max(lags_sequence)\n",
    "- Not sure what feature_size is actually representing here but I force it to the same size as mat1 dim 2 currently (errors otherwise)\n",
    "- No idea why last_hidden_state is an empty tensor currently...\n",
    "- Currently assuming encoder_last_hidden_state is what I want to use as it is the TS embeddings w/o prediction\n",
    "- mat1 dim 2 effective change seems to be changing lags_sequence (seems to be addition of this) \n",
    "- mat 1 dim 2 also effected by past_time_features num_features (third dim) (concatenation of len(lags_sequence), num_features of past_time_features and something else)\n",
    "- unaccounted for about 2 of mat1 dim 2\n",
    "\"\"\"\n",
    "model = TimeSeriesTransformerModel(config)\n",
    "\n",
    "import data_helper_v2 as dh\n",
    "\n",
    "df = dh.get_data(data_source=\"stock_emotions\", text_window=k)\n",
    "\n",
    "\n",
    "past_values = torch.tensor([[x[0] for x in df.iloc[0][\"time_series\"]]])  #torch.rand(32, k)  \n",
    "past_observed_mask = torch.ones(1, k)\n",
    "past_time_features = torch.tensor([df.iloc[0][\"past_time_features\"]])  #torch.rand(32, k, num_features) \n",
    "\n",
    "encoder_outputs = model(past_values = past_values, past_observed_mask=past_observed_mask, past_time_features=past_time_features)\n",
    "\n",
    "last_hidden_state = encoder_outputs.encoder_last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[74.9500, 74.5975, 75.7975, 77.4075, 77.5825]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0151, 0.3117, 0.9731, 0.0984, 0.4636, 0.7775, 0.7680]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75.79750061035156,\n",
       " 77.40750122070312,\n",
       " 77.5824966430664,\n",
       " 79.23999786376953,\n",
       " 78.16999816894531]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in df.iloc[0][\"time_series\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[75.7975, 77.4075, 77.5825, 79.2400, 78.1700]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[x[0] for x in df.iloc[0][\"time_series\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4089, 0.0124],\n",
       "         [0.9518, 0.9166],\n",
       "         [0.8431, 0.0772],\n",
       "         [0.9122, 0.3923],\n",
       "         [0.1055, 0.9232],\n",
       "         [0.2908, 0.9051],\n",
       "         [0.2939, 0.4366]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1, k, num_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  8],\n",
       "         [ 1,  9],\n",
       "         [ 1, 10],\n",
       "         [ 1, 13],\n",
       "         [ 1, 14]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([df.iloc[0][\"past_time_features\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import data_helper_v2 as dh\n",
    "import model_helper as mh\n",
    "\n",
    "model = mh.get_model(ts_encoder_config={\"name\": 'TSTransformerBaseEncoder'}, text_encoder_config={\"name\": 'bert-base-uncased', \"auto-pre-trained\": True})\n",
    "\n",
    "df = dh.get_data(data_source=\"stock_emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-01-06 00:00:00')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"all_dates\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_time_features = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    past_time_features_this_row = []\n",
    "\n",
    "    for i in row[\"all_dates\"]:\n",
    "        past_time_features_this_row.append([i.month, i.day])\n",
    "    past_time_features.append(past_time_features_this_row)\n",
    "\n",
    "df[\"past_time_features\"] = past_time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[74.94999694824219],\n",
       " [74.59750366210938],\n",
       " [75.79750061035156],\n",
       " [77.40750122070312],\n",
       " [77.5824966430664]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"time_series\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import data_helper_v2 as dh\n",
    "import model_helper as mh\n",
    "\n",
    "k = 5\n",
    "model = mh.get_model(ts_encoder_config={\"name\": 'TSTransformerBaseEncoder'}, text_encoder_config={\"name\": 'bert-base-uncased', \"auto-pre-trained\": True}, ts_window=k, projection_dim=64)\n",
    "\n",
    "train_dl, val_dl, test_dl = dh.get_data(data_source=\"stock_emotions\", text_window=k, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data, text_data, attention_mask, labels = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(ts_data, text_data, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5109,  0.7433,  0.6212,  ..., -0.4158, -0.1499, -0.0985],\n",
       "         [ 0.4460,  0.6723,  0.7150,  ..., -0.6024, -0.1907, -0.1959],\n",
       "         [ 0.2519,  0.7894,  0.5399,  ..., -0.0990, -0.2310, -0.0908],\n",
       "         ...,\n",
       "         [ 0.7234,  0.7159,  0.8925,  ..., -0.2425, -0.1156, -0.4226],\n",
       "         [ 0.5348,  0.7593,  0.7750,  ..., -0.2100, -0.3418, -0.4217],\n",
       "         [ 0.8623,  0.2707,  0.3548,  ..., -0.8024, -0.0737, -0.3250]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.4801, -0.1925, -0.0143,  ...,  0.4680, -0.6325, -0.2222],\n",
       "         [-0.2777, -0.0268, -0.1001,  ...,  0.6788, -0.3936, -0.1620],\n",
       "         [-0.5431, -0.0561, -0.2057,  ...,  0.4448, -0.5041,  0.0032],\n",
       "         ...,\n",
       "         [-0.2928, -0.3931, -0.1864,  ...,  0.4848, -0.7334, -0.2361],\n",
       "         [-0.4708, -0.0714, -0.0946,  ...,  0.5001, -0.4944, -0.0937],\n",
       "         [-0.5658,  0.1682, -0.0173,  ...,  0.4210, -0.3193, -0.0975]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mh.cosine_similarity_custom(output[0].detach().numpy(), output[1].detach().numpy())\n",
    "\n",
    "all_preds = (preds >= 0.5).astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
